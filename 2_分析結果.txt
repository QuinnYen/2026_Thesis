正在啟動BERT情感分析系統...
2025-07-29 20:06:36,911 - INFO - 已創建新的執行目錄：D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:06:36,911 - INFO - 已創建統一編碼目錄：02_encoding
2025-07-29 20:07:00,224 - INFO - 📁 已確保run目錄結構存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:07:00,238 - INFO - 📋 已創建輸入文件參考: D:/Quinn_Small_House/2026_Thesis/2026_Thesis/data/IMDB/IMDB Dataset.csv
正在下載 NLTK 資源: wordnet
NLTK 資源初始化完成
2025-07-29 20:07:32,922 - INFO - 📁 已確保run目錄結構存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:07:33,738 - INFO - ✅ 已儲存處理數據到: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\01_preprocessing\01_preprocessed_data.csv (50000 行)
2025-07-29 20:19:45,006 - INFO - 📁 已確保run目錄結構存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:19:45,086 - INFO - ✅ 已儲存BERT特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy (50000, 768)
2025-07-29 20:19:45,890 - INFO - ✅ 已儲存處理數據到: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\step3_vectorized_data.csv (50000 行)
🎯 檢測到GNF動態權重注意力，將使用神經網路自適應權重調整
2025-07-29 20:20:00,298 - INFO - 檢測到GPU環境: NVIDIA GeForce RTX 5070

================================================================================       
🚀 開始執行多重注意力機制組合分析
================================================================================       
2025-07-29 20:20:00,517 - INFO - 📁 已確保run目錄結構存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:20:00,517 - INFO - 注意力處理器已初始化，使用 BERT 編碼器
2025-07-29 20:20:00,517 - INFO - 📁 儲存管理器已啟用，將優化檔案儲存

📋 分析配置:
   • 輸入文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\step3_vectorized_data.csv
   • 輸出目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636 
   • 基本注意力機制: no, similarity, keyword, self, dynamic
   • 組合配置數量: 0

🔬 階段 1/3: 基本注意力機制分析
--------------------------------------------------
2025-07-29 20:20:01,090 - INFO - ============================================================
2025-07-29 20:20:01,090 - INFO - 開始注意力機制分析流程
2025-07-29 20:20:01,090 - INFO - ============================================================

📊 步驟 1/6: 讀取數據...
2025-07-29 20:20:01,090 - INFO - 讀取數據: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\step3_vectorized_data.csv
✅ 成功讀取 50000 條數據
2025-07-29 20:20:01,667 - INFO - 成功讀取 50000 條數據
2025-07-29 20:20:01,668 - INFO - 📋 已創建輸入文件參考: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\step3_vectorized_data.csv

🔍 步驟 2/6: 檢查數據欄位...
2025-07-29 20:20:01,670 - INFO - 使用文本欄位: processed_text
✅ 使用文本欄位: processed_text

🤖 步驟 3/6: 處理BERT特徵向量...
2025-07-29 20:20:01,670 - INFO - 🔍 發現當前run中的BERT特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy   
   📂 發現已存在的 BERT 特徵向量文件，正在載入...
2025-07-29 20:20:01,670 - INFO - 載入已存在的BERT特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy
   ✅ BERT特徵向量載入完成 (形狀: (50000, 768))
2025-07-29 20:20:01,717 - INFO - BERT特徵向量形狀: (50000, 768)
✅ 特徵向量準備完成 (形狀: (50000, 768))

📋 步驟 4/6: 準備元數據...
2025-07-29 20:20:01,721 - INFO - 情感標籤分布: {'positive': 25000, 'negative': 25000}  
✅ 元數據準備完成

⚙️ 步驟 5/6: 初始化注意力分析器...
2025-07-29 20:20:01,721 - INFO - 找到主題標籤文件: Part05_/utils/topic_labels.json     
2025-07-29 20:20:01,723 - INFO - 成功載入主題標籤: Part05_/utils/topic_labels.json     
✅ 注意力分析器已初始化

🔬 步驟 6/6: 執行注意力機制分析...
將測試以下注意力機制: no, similarity, keyword, self, dynamic
2025-07-29 20:20:01,729 - INFO - 開始分析 5 種注意力機制
分析注意力機制:   0%|                                           | 0/5 [00:00<?, ?it/s]2025-07-29 20:20:01,730 - INFO - 分析注意力機制: no
2025-07-29 20:20:02,145 - INFO - 
總體內聚度: 0.9312
2025-07-29 20:20:02,145 - INFO - 總體分離度: 0.0033
2025-07-29 20:20:02,145 - INFO -
綜合得分: 0.4672 (內聚度權重: 0.5, 分離度權重: 0.5)
2025-07-29 20:20:02,145 - INFO -    ✅ no 注意力完成 - 內聚度: 0.9312, 分離度: 0.0033, 綜合得分: 0.4672
2025-07-29 20:20:02,145 - INFO - no 注意力 - 內聚度: 0.9312, 分離度: 0.0033, 綜合得分: 0.4672
分析注意力機制:  20%|███████                            | 1/5 [00:00<00:01,  2.41it/s]2025-07-29 20:20:02,146 - INFO - 分析注意力機制: similarity
2025-07-29 20:20:02,707 - INFO - 
總體內聚度: 0.9311
2025-07-29 20:20:02,707 - INFO - 總體分離度: 0.0033
2025-07-29 20:20:02,708 - INFO -
綜合得分: 0.4672 (內聚度權重: 0.5, 分離度權重: 0.5)
2025-07-29 20:20:02,708 - INFO -    ✅ similarity 注意力完成 - 內聚度: 0.9311, 分離度: 0.0033, 綜合得分: 0.4672
2025-07-29 20:20:02,708 - INFO - similarity 注意力 - 內聚度: 0.9311, 分離度: 0.0033, 綜合得分: 0.4672
分析注意力機制:  40%|██████████████                     | 2/5 [00:00<00:01,  1.99it/s]2025-07-29 20:20:02,708 - INFO - 分析注意力機制: keyword
2025-07-29 20:20:02,708 - INFO - 使用預設關鍵詞進行注意力計算
2025-07-29 20:20:03,223 - INFO - 
總體內聚度: 0.9281
2025-07-29 20:20:03,223 - INFO - 總體分離度: 0.0056
2025-07-29 20:20:03,223 - INFO -
綜合得分: 0.4668 (內聚度權重: 0.5, 分離度權重: 0.5)
2025-07-29 20:20:03,223 - INFO -    ✅ keyword 注意力完成 - 內聚度: 0.9281, 分離度: 0.0056, 綜合得分: 0.4668
2025-07-29 20:20:03,223 - INFO - keyword 注意力 - 內聚度: 0.9281, 分離度: 0.0056, 綜合 得分: 0.4668
分析注意力機制:  60%|█████████████████████              | 3/5 [00:01<00:01,  1.97it/s]2025-07-29 20:20:03,223 - INFO - 分析注意力機制: self
2025-07-29 20:20:03,226 - INFO - 🔧 SelfAttention 使用設備: cuda
2025-07-29 20:20:04,026 - INFO - 
總體內聚度: 0.9312
2025-07-29 20:20:04,026 - INFO - 總體分離度: 0.0033
2025-07-29 20:20:04,026 - INFO -
綜合得分: 0.4672 (內聚度權重: 0.5, 分離度權重: 0.5)
2025-07-29 20:20:04,026 - INFO -    ✅ self 注意力完成 - 內聚度: 0.9312, 分離度: 0.0033, 綜合得分: 0.4672
2025-07-29 20:20:04,026 - INFO - self 注意力 - 內聚度: 0.9312, 分離度: 0.0033, 綜合得分: 0.4672
分析注意力機制:  80%|████████████████████████████       | 4/5 [00:02<00:00,  1.60it/s]2025-07-29 20:20:04,027 - INFO - 分析注意力機制: dynamic
2025-07-29 20:20:04,030 - INFO - 🔧 DynamicCombinedAttention 使用設備: cuda
2025-07-29 20:20:04,064 - INFO -    GPU記憶體已清理: NVIDIA GeForce RTX 5070
2025-07-29 20:20:04,064 - INFO -    可用GPU記憶體: 11.9GB
2025-07-29 20:20:04,064 - INFO - 🎯 開始動態注意力計算 (嵌入向量形狀: (50000, 768))    
2025-07-29 20:20:04,064 - INFO -    🔧 初始化GatedFusionNetwork (輸入維度: 15, 設備: cuda)
2025-07-29 20:20:04,066 - INFO -    ✅ GatedFusionNetwork 已成功初始化並移至 cuda      
2025-07-29 20:20:04,066 - INFO -    GPU記憶體使用: 8.2MB
2025-07-29 20:20:05,065 - INFO - 🔍 GatedFusionNetwork 動態權重詳細資訊:
2025-07-29 20:20:05,065 - INFO -    動態權重張量形狀: (50000, 3)
2025-07-29 20:20:05,065 - INFO -    平均後的權重字典: {'similarity': 0.25885477662086487, 'keyword': 0.3768858313560486, 'self': 0.3642594516277313}
2025-07-29 20:20:05,065 - INFO -    權重統計 - 總和: 1.000000, 最小值: 0.258855, 最大值: 0.376886
2025-07-29 20:20:05,065 - INFO - ✅ 動態權重計算完成
2025-07-29 20:20:05,065 - INFO - 🔍 _compute_weighted_attention 輸入權重: {'similarity': 0.25885477662086487, 'keyword': 0.3768858313560486, 'self': 0.3642594516277313}      
2025-07-29 20:20:05,066 - INFO -    過濾閾值: 1e-06
2025-07-29 20:20:05,066 - INFO -    過濾後的有效權重: {'similarity': 0.25885477662086487, 'keyword': 0.3768858313560486, 'self': 0.3642594516277313}
2025-07-29 20:20:05,066 - INFO - ✅ 使用有效權重進行動態注意力計算: {'similarity': 0.25885477662086487, 'keyword': 0.3768858313560486, 'self': 0.3642594516277313}
2025-07-29 20:20:05,280 - INFO - 使用預設關鍵詞進行注意力計算
2025-07-29 20:20:05,453 - INFO - 🔧 SelfAttention 使用設備: cuda
2025-07-29 20:20:05,878 - ERROR - 處理 dynamic 注意力機制時發生錯誤: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
分析注意力機制: 100%|███████████████████████████████████| 5/5 [00:04<00:00,  1.21it/s]
2025-07-29 20:20:05,878 - INFO - 注意力機制比較完成。最佳機制: self

🎉 注意力機制分析完成！
📊 總耗時: 4.79 秒
🏆 最佳注意力機制: self
📈 最佳綜合得分: 0.4672
2025-07-29 20:20:05,878 - INFO - 注意力機制分析完成，耗時 4.79 秒

⏭️ 跳過組合分析階段（無組合配置）

🎯 階段 3/3: 分類性能評估
--------------------------------------------------
2025-07-29 20:20:05,879 - INFO - 開始執行分類評估...
2025-07-29 20:20:05,903 - INFO - 🚀 GPU加速已啟用
2025-07-29 20:20:05,903 - INFO - XGBoost已成功載入並配置
2025-07-29 20:20:05,903 - INFO - 情感分類器已初始化
   🔍 載入 BERT 嵌入向量用於分類評估...
2025-07-29 20:20:05,904 - INFO - 📁 已確保run目錄結構存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:20:05,904 - INFO - 注意力處理器已初始化，使用 BERT 編碼器
2025-07-29 20:20:05,905 - INFO - 📁 儲存管理器已啟用，將優化檔案儲存
2025-07-29 20:20:05,905 - INFO - 在目錄中搜索 BERT 特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output
2025-07-29 20:20:05,905 - INFO - 找到 4 個run目錄: ['run_20250729_192358', 'run_20250729_192850', 'run_20250729_195430', 'run_20250729_200636']
2025-07-29 20:20:05,905 - WARNING - 無法導入路徑配置模組: attempted relative import beyond top-level package，使用舊方法
2025-07-29 20:20:05,905 - INFO - 檢查run目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358
2025-07-29 20:20:05,905 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358\02_encoding (存在: True)
2025-07-29 20:20:05,905 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358\02_encoding\02_bert_embeddings.npy (存在: False)
2025-07-29 20:20:05,905 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358\02_encoding\bert_embeddings.npy (存在: False)
2025-07-29 20:20:05,905 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358\02_encoding\embeddings.npy (存在: False)
2025-07-29 20:20:05,905 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192358\02_bert_encoding (存在: False)
2025-07-29 20:20:05,905 - INFO - 檢查run目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850
2025-07-29 20:20:05,905 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850\02_encoding (存在: True)
2025-07-29 20:20:05,905 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850\02_encoding\02_bert_embeddings.npy (存在: True)
2025-07-29 20:20:05,906 - INFO - 驗證文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850\02_encoding\02_bert_embeddings.npy
2025-07-29 20:20:05,906 - INFO - 驗證文件: 02_bert_embeddings.npy, 編碼器類型: bert    
2025-07-29 20:20:05,906 - INFO - ✅ 驗證通過: 檔案名包含編碼器類型 'bert'
2025-07-29 20:20:05,906 - INFO - ✅ 找到並驗證 BERT 特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850\02_encoding\02_bert_embeddings.npy      
2025-07-29 20:20:05,906 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_192850\02_bert_encoding (存在: False)
2025-07-29 20:20:05,906 - INFO - 檢查run目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430
2025-07-29 20:20:05,906 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430\02_encoding (存在: True)
2025-07-29 20:20:05,906 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430\02_encoding\02_bert_embeddings.npy (存在: False)
2025-07-29 20:20:05,906 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430\02_encoding\bert_embeddings.npy (存在: False)
2025-07-29 20:20:05,906 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430\02_encoding\embeddings.npy (存在: False)
2025-07-29 20:20:05,906 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_195430\02_bert_encoding (存在: False)
2025-07-29 20:20:05,906 - INFO - 檢查run目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
2025-07-29 20:20:05,906 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding (存在: True)
2025-07-29 20:20:05,906 - INFO - 檢查文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy (存在: True)
2025-07-29 20:20:05,906 - INFO - 驗證文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy
2025-07-29 20:20:05,906 - INFO - 驗證文件: 02_bert_embeddings.npy, 編碼器類型: bert    
2025-07-29 20:20:05,906 - INFO - ✅ 驗證通過: 檔案名包含編碼器類型 'bert'
2025-07-29 20:20:05,906 - INFO - ✅ 找到並驗證 BERT 特徵向量: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy      
2025-07-29 20:20:05,906 - INFO - 檢查編碼目錄: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_bert_encoding (存在: False)
2025-07-29 20:20:05,907 - INFO - 選擇最新的 BERT 特徵向量文件: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy     
   ✅ 已載入 BERT 嵌入向量，形狀: (50000, 768)
   📁 來源檔案: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\02_encoding\02_bert_embeddings.npy
2025-07-29 20:20:05,951 - INFO - 載入 BERT 嵌入向量: (50000, 768)
🔍 檢查注意力結果，總共 6 個項目:
   - no: <class 'dict'>
     鍵: ['aspect_vectors', 'attention_data', 'metrics', 'attention_type']
   ✅ no 有效，包含aspect_vectors
   - similarity: <class 'dict'>
     鍵: ['aspect_vectors', 'attention_data', 'metrics', 'attention_type']
   ✅ similarity 有效，包含aspect_vectors
   - keyword: <class 'dict'>
     鍵: ['aspect_vectors', 'attention_data', 'metrics', 'attention_type']
   ✅ keyword 有效，包含aspect_vectors
   - self: <class 'dict'>
     鍵: ['aspect_vectors', 'attention_data', 'metrics', 'attention_type']
   ✅ self 有效，包含aspect_vectors
   - comparison: <class 'dict'>
     鍵: ['coherence_ranking', 'separation_ranking', 'combined_ranking', 'summary']    
   ❌ comparison 無效或缺少aspect_vectors
   - processing_info: <class 'dict'>
     鍵: ['start_time', 'end_time', 'processing_time_seconds', 'input_file', 'data_samples', 'text_column', 'embeddings_shape', 'attention_types_tested']
   ❌ processing_info 無效或缺少aspect_vectors
📊 開始評估 4 種注意力機制的分類性能...
評估注意力機制:   0%|                                           | 0/4 [00:00<?, ?it/s]   🔍 正在評估 no 注意力機制...
2025-07-29 20:20:05,952 - INFO - 評估 no 注意力機制的分類性能...
      📋 準備特徵向量...
2025-07-29 20:20:05,952 - INFO - 開始準備分類特徵...
2025-07-29 20:20:05,982 - INFO - 計算每個文檔與 2 個面向向量的相似度...
2025-07-29 20:20:06,457 - INFO - 特徵準備完成，耗時: 0.51 秒
2025-07-29 20:20:06,458 - INFO - 準備了 50000 個樣本，770 維特徵
2025-07-29 20:20:06,458 - INFO -   - 原始BERT特徵: 768 維
2025-07-29 20:20:06,458 - INFO -   - 面向相似度特徵: 2 維
2025-07-29 20:20:06,458 - INFO - 使用的面向: ['negative', 'positive']
2025-07-29 20:20:06,466 - INFO - 標籤分布: {'negative': np.int64(25000), 'positive': np.int64(25000)}
      🤖 訓練分類器...
2025-07-29 20:20:06,466 - INFO - 開始訓練 xgboost 模型...
2025-07-29 20:20:06,466 - INFO - 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)       
2025-07-29 20:20:06,553 - INFO - 數據分割完成，耗時: 0.09 秒
2025-07-29 20:20:06,553 - INFO - 訓練集大小: 40000, 測試集大小: 10000
2025-07-29 20:20:06,554 - INFO - 開始訓練模型...
2025-07-29 20:20:06,554 - INFO - 🚀 使用GPU加速XGBoost訓練...
2025-07-29 20:20:06,554 - INFO - 正在優化數據格式以支援GPU加速...
2025-07-29 20:20:06,630 - INFO - ✅ 數據已優化為GPU兼容格式
2025-07-29 20:20:06,630 - INFO - XGBoost 2.0+: 確認GPU模式已啟用 (device='cuda')
2025-07-29 20:20:13,862 - INFO - 模型訓練完成，耗時: 7.31 秒
2025-07-29 20:20:13,862 - INFO - 開始預測...
[20:20:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\common\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

2025-07-29 20:20:14,243 - INFO - 預測完成，耗時: 0.38 秒
🔍 加權平均 vs 宏平均比較：
   精確率 - 加權: 0.823013, 宏: 0.823013
   召回率 - 加權: 0.823000, 宏: 0.823000
   F1分數 - 加權: 0.822998, 宏: 0.822998
⚠️  注意：準確率、精確率、召回率非常接近，可能原因：
   1. 數據集高度平衡
   2. 模型性能極佳
   3. 使用加權平均導致指標趨同
   建議查看宏平均和各類別指標以獲得更詳細分析
🔍 指標調試：
   測試準確率: 0.823000
   測試精確率: 0.823013
   測試召回率: 0.823000
   測試F1分數: 0.822998
🔍 測試集類別分佈: {np.int64(0): np.int64(5000), np.int64(1): np.int64(5000)}
🔍 混淆矩陣:
[[4131  869]
 [ 901 4099]]
🔍 各類別精確率: [0.82094595 0.82508052]
🔍 各類別召回率: [0.8262 0.8198]
🔍 各類別F1分數: [0.82356459 0.82243178]
🔍 各類別支持數: [5000 5000]
🔍 預測值種類: [0 1]
🔍 預測準確率分佈: [0.5032 0.4968]
2025-07-29 20:20:14,268 - INFO - 模型已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\sentiment_classifier_xgboost.pkl
2025-07-29 20:20:14,268 - INFO - 標籤編碼器已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\label_encoder.pkl
2025-07-29 20:20:14,269 - INFO - 🕐 模型訓練完整統計:
2025-07-29 20:20:14,269 - INFO -    • 總耗時: 7.79 秒
2025-07-29 20:20:14,269 - INFO -    • 數據分割: 0.09 秒
2025-07-29 20:20:14,269 - INFO -    • 模型訓練: 7.31 秒
2025-07-29 20:20:14,269 - INFO -    • 預測時間: 0.38 秒
2025-07-29 20:20:14,269 - INFO -    • 測試準確率: 0.8230
2025-07-29 20:20:14,269 - INFO -    • 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)  
      ✅ no 評估完成 - 準確率: 0.8230, F1分數: 0.8230
評估注意力機制:  25%|████████▊                          | 1/4 [00:08<00:24,  8.32s/it]   🔍 正在評估 similarity 注意力機制...
2025-07-29 20:20:14,270 - INFO - 評估 similarity 注意力機制的分類性能...
      📋 準備特徵向量...
2025-07-29 20:20:14,270 - INFO - 開始準備分類特徵...
2025-07-29 20:20:14,302 - INFO - 計算每個文檔與 2 個面向向量的相似度...
2025-07-29 20:20:14,767 - INFO - 特徵準備完成，耗時: 0.50 秒
2025-07-29 20:20:14,768 - INFO - 準備了 50000 個樣本，770 維特徵
2025-07-29 20:20:14,768 - INFO -   - 原始BERT特徵: 768 維
2025-07-29 20:20:14,768 - INFO -   - 面向相似度特徵: 2 維
2025-07-29 20:20:14,768 - INFO - 使用的面向: ['negative', 'positive']
2025-07-29 20:20:14,776 - INFO - 標籤分布: {'negative': np.int64(25000), 'positive': np.int64(25000)}
      🤖 訓練分類器...
2025-07-29 20:20:14,777 - INFO - 開始訓練 xgboost 模型...
2025-07-29 20:20:14,777 - INFO - 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)       
2025-07-29 20:20:14,870 - INFO - 數據分割完成，耗時: 0.09 秒
2025-07-29 20:20:14,870 - INFO - 訓練集大小: 40000, 測試集大小: 10000
2025-07-29 20:20:14,870 - INFO - 開始訓練模型...
2025-07-29 20:20:14,870 - INFO - 🚀 使用GPU加速XGBoost訓練...
2025-07-29 20:20:14,870 - INFO - 正在優化數據格式以支援GPU加速...
2025-07-29 20:20:14,933 - INFO - ✅ 數據已優化為GPU兼容格式
2025-07-29 20:20:14,933 - INFO - XGBoost 2.0+: 確認GPU模式已啟用 (device='cuda')
2025-07-29 20:20:16,541 - INFO - 模型訓練完成，耗時: 1.67 秒
2025-07-29 20:20:16,541 - INFO - 開始預測...
2025-07-29 20:20:16,935 - INFO - 預測完成，耗時: 0.39 秒
🔍 加權平均 vs 宏平均比較：
   精確率 - 加權: 0.825428, 宏: 0.825428
   召回率 - 加權: 0.825400, 宏: 0.825400
   F1分數 - 加權: 0.825396, 宏: 0.825396
⚠️  注意：準確率、精確率、召回率非常接近，可能原因：
   1. 數據集高度平衡
   2. 模型性能極佳
   3. 使用加權平均導致指標趨同
   建議查看宏平均和各類別指標以獲得更詳細分析
🔍 指標調試：
   測試準確率: 0.825400
   測試精確率: 0.825428
   測試召回率: 0.825400
   測試F1分數: 0.825396
🔍 測試集類別分佈: {np.int64(0): np.int64(5000), np.int64(1): np.int64(5000)}
🔍 混淆矩陣:
[[4150  850]
 [ 896 4104]]
🔍 各類別精確率: [0.82243361 0.82842148]
🔍 各類別召回率: [0.83   0.8208]
🔍 各類別F1分數: [0.82619948 0.82459313]
🔍 各類別支持數: [5000 5000]
🔍 預測值種類: [0 1]
🔍 預測準確率分佈: [0.5046 0.4954]
2025-07-29 20:20:16,958 - INFO - 模型已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\sentiment_classifier_xgboost.pkl
2025-07-29 20:20:16,958 - INFO - 標籤編碼器已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\label_encoder.pkl
2025-07-29 20:20:16,958 - INFO - 🕐 模型訓練完整統計:
2025-07-29 20:20:16,958 - INFO -    • 總耗時: 2.17 秒
2025-07-29 20:20:16,958 - INFO -    • 數據分割: 0.09 秒
2025-07-29 20:20:16,958 - INFO -    • 模型訓練: 1.67 秒
2025-07-29 20:20:16,958 - INFO -    • 預測時間: 0.39 秒
2025-07-29 20:20:16,958 - INFO -    • 測試準確率: 0.8254
2025-07-29 20:20:16,958 - INFO -    • 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)  
      ✅ similarity 評估完成 - 準確率: 0.8254, F1分數: 0.8254
評估注意力機制:  50%|█████████████████▌                 | 2/4 [00:11<00:10,  5.01s/it]   🔍 正在評估 keyword 注意力機制...
2025-07-29 20:20:16,959 - INFO - 評估 keyword 注意力機制的分類性能...
      📋 準備特徵向量...
2025-07-29 20:20:16,959 - INFO - 開始準備分類特徵...
2025-07-29 20:20:16,987 - INFO - 計算每個文檔與 2 個面向向量的相似度...
2025-07-29 20:20:17,462 - INFO - 特徵準備完成，耗時: 0.50 秒
2025-07-29 20:20:17,462 - INFO - 準備了 50000 個樣本，770 維特徵
2025-07-29 20:20:17,462 - INFO -   - 原始BERT特徵: 768 維
2025-07-29 20:20:17,463 - INFO -   - 面向相似度特徵: 2 維
2025-07-29 20:20:17,463 - INFO - 使用的面向: ['negative', 'positive']
2025-07-29 20:20:17,472 - INFO - 標籤分布: {'negative': np.int64(25000), 'positive': np.int64(25000)}
      🤖 訓練分類器...
2025-07-29 20:20:17,472 - INFO - 開始訓練 xgboost 模型...
2025-07-29 20:20:17,472 - INFO - 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)       
2025-07-29 20:20:17,574 - INFO - 數據分割完成，耗時: 0.10 秒
2025-07-29 20:20:17,575 - INFO - 訓練集大小: 40000, 測試集大小: 10000
2025-07-29 20:20:17,575 - INFO - 開始訓練模型...
2025-07-29 20:20:17,575 - INFO - 🚀 使用GPU加速XGBoost訓練...
2025-07-29 20:20:17,575 - INFO - 正在優化數據格式以支援GPU加速...
2025-07-29 20:20:17,654 - INFO - ✅ 數據已優化為GPU兼容格式
2025-07-29 20:20:17,654 - INFO - XGBoost 2.0+: 確認GPU模式已啟用 (device='cuda')
2025-07-29 20:20:19,252 - INFO - 模型訓練完成，耗時: 1.68 秒
2025-07-29 20:20:19,252 - INFO - 開始預測...
2025-07-29 20:20:19,626 - INFO - 預測完成，耗時: 0.37 秒
🔍 加權平均 vs 宏平均比較：
   精確率 - 加權: 0.821308, 宏: 0.821308
   召回率 - 加權: 0.821300, 宏: 0.821300
   F1分數 - 加權: 0.821299, 宏: 0.821299
⚠️  注意：準確率、精確率、召回率非常接近，可能原因：
   1. 數據集高度平衡
   2. 模型性能極佳
   3. 使用加權平均導致指標趨同
   建議查看宏平均和各類別指標以獲得更詳細分析
🔍 指標調試：
   測試準確率: 0.821300
   測試精確率: 0.821308
   測試召回率: 0.821300
   測試F1分數: 0.821299
🔍 測試集類別分佈: {np.int64(0): np.int64(5000), np.int64(1): np.int64(5000)}
🔍 混淆矩陣:
[[4119  881]
 [ 906 4094]]
🔍 各類別精確率: [0.81970149 0.82291457]
🔍 各類別召回率: [0.8238 0.8188]
🔍 各類別F1分數: [0.82174564 0.82085213]
🔍 各類別支持數: [5000 5000]
🔍 預測值種類: [0 1]
🔍 預測準確率分佈: [0.5025 0.4975]
2025-07-29 20:20:19,650 - INFO - 模型已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\sentiment_classifier_xgboost.pkl
2025-07-29 20:20:19,650 - INFO - 標籤編碼器已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\label_encoder.pkl
2025-07-29 20:20:19,650 - INFO - 🕐 模型訓練完整統計:
2025-07-29 20:20:19,650 - INFO -    • 總耗時: 2.17 秒
2025-07-29 20:20:19,650 - INFO -    • 數據分割: 0.10 秒
2025-07-29 20:20:19,650 - INFO -    • 模型訓練: 1.68 秒
2025-07-29 20:20:19,650 - INFO -    • 預測時間: 0.37 秒
2025-07-29 20:20:19,650 - INFO -    • 測試準確率: 0.8213
2025-07-29 20:20:19,650 - INFO -    • 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)  
      ✅ keyword 評估完成 - 準確率: 0.8213, F1分數: 0.8213
評估注意力機制:  75%|██████████████████████████▎        | 3/4 [00:13<00:03,  3.95s/it]   🔍 正在評估 self 注意力機制...
2025-07-29 20:20:19,651 - INFO - 評估 self 注意力機制的分類性能...
      📋 準備特徵向量...
2025-07-29 20:20:19,651 - INFO - 開始準備分類特徵...
2025-07-29 20:20:19,680 - INFO - 計算每個文檔與 2 個面向向量的相似度...
2025-07-29 20:20:20,157 - INFO - 特徵準備完成，耗時: 0.51 秒
2025-07-29 20:20:20,157 - INFO - 準備了 50000 個樣本，770 維特徵
2025-07-29 20:20:20,157 - INFO -   - 原始BERT特徵: 768 維
2025-07-29 20:20:20,157 - INFO -   - 面向相似度特徵: 2 維
2025-07-29 20:20:20,157 - INFO - 使用的面向: ['negative', 'positive']
2025-07-29 20:20:20,167 - INFO - 標籤分布: {'negative': np.int64(25000), 'positive': np.int64(25000)}
      🤖 訓練分類器...
2025-07-29 20:20:20,167 - INFO - 開始訓練 xgboost 模型...
2025-07-29 20:20:20,167 - INFO - 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)       
2025-07-29 20:20:20,282 - INFO - 數據分割完成，耗時: 0.11 秒
2025-07-29 20:20:20,282 - INFO - 訓練集大小: 40000, 測試集大小: 10000
2025-07-29 20:20:20,282 - INFO - 開始訓練模型...
2025-07-29 20:20:20,282 - INFO - 🚀 使用GPU加速XGBoost訓練...
2025-07-29 20:20:20,282 - INFO - 正在優化數據格式以支援GPU加速...
2025-07-29 20:20:20,368 - INFO - ✅ 數據已優化為GPU兼容格式
2025-07-29 20:20:20,368 - INFO - XGBoost 2.0+: 確認GPU模式已啟用 (device='cuda')
2025-07-29 20:20:21,946 - INFO - 模型訓練完成，耗時: 1.66 秒
2025-07-29 20:20:21,946 - INFO - 開始預測...
2025-07-29 20:20:22,344 - INFO - 預測完成，耗時: 0.40 秒
🔍 加權平均 vs 宏平均比較：
   精確率 - 加權: 0.823013, 宏: 0.823013
   召回率 - 加權: 0.823000, 宏: 0.823000
   F1分數 - 加權: 0.822998, 宏: 0.822998
⚠️  注意：準確率、精確率、召回率非常接近，可能原因：
   1. 數據集高度平衡
   2. 模型性能極佳
   3. 使用加權平均導致指標趨同
   建議查看宏平均和各類別指標以獲得更詳細分析
🔍 指標調試：
   測試準確率: 0.823000
   測試精確率: 0.823013
   測試召回率: 0.823000
   測試F1分數: 0.822998
🔍 測試集類別分佈: {np.int64(0): np.int64(5000), np.int64(1): np.int64(5000)}
🔍 混淆矩陣:
[[4131  869]
 [ 901 4099]]
🔍 各類別精確率: [0.82094595 0.82508052]
🔍 各類別召回率: [0.8262 0.8198]
🔍 各類別F1分數: [0.82356459 0.82243178]
🔍 各類別支持數: [5000 5000]
🔍 預測值種類: [0 1]
🔍 預測準確率分佈: [0.5032 0.4968]
2025-07-29 20:20:22,368 - INFO - 模型已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\sentiment_classifier_xgboost.pkl
2025-07-29 20:20:22,368 - INFO - 標籤編碼器已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\label_encoder.pkl
2025-07-29 20:20:22,368 - INFO - 🕐 模型訓練完整統計:
2025-07-29 20:20:22,368 - INFO -    • 總耗時: 2.19 秒
2025-07-29 20:20:22,368 - INFO -    • 數據分割: 0.11 秒
2025-07-29 20:20:22,368 - INFO -    • 模型訓練: 1.66 秒
2025-07-29 20:20:22,368 - INFO -    • 預測時間: 0.40 秒
2025-07-29 20:20:22,368 - INFO -    • 測試準確率: 0.8230
2025-07-29 20:20:22,369 - INFO -    • 計算環境: GPU: NVIDIA GeForce RTX 5070 (11.9GB)  
      ✅ self 評估完成 - 準確率: 0.8230, F1分數: 0.8230
評估注意力機制: 100%|███████████████████████████████████| 4/4 [00:16<00:00,  4.10s/it] 
   📈 比較不同注意力機制的性能...
✅ 分類性能評估完成！
🏆 最佳分類性能機制: similarity
📊 最佳準確率: 0.8254
📊 最佳F1分數: 0.8254

📊 整合分析結果...

🏆 最終評估結果:
   • 最佳注意力機制: similarity
   • 最佳分類準確率: 0.8254
   • 最佳F1分數: 0.8254
   • 測試機制總數: 5
   • 組合配置數量: 0
2025-07-29 20:20:22,370 - INFO - 評估完成！最佳注意力機制: similarity
2025-07-29 20:20:22,370 - INFO - 最佳分類準確率: 0.8254
2025-07-29 20:20:22,370 - INFO - 最佳F1分數: 0.8254

💾 保存完整分析結果...
✅ 完整結果已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\multiple_combinations_analysis_results.json
2025-07-29 20:20:23,223 - INFO - 完整結果已保存至: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636\multiple_combinations_analysis_results.json        

🎉 多重組合分析完成！
📁 所有結果保存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
================================================================================       
2025-07-29 20:20:23,223 - INFO - 多重組合分析結果保存在: D:\Quinn_Small_House\2026_Thesis\2026_Thesis\output\run_20250729_200636
🔍 GUI除錯：開始更新分析結果...
🔍 GUI除錯：results的鍵: ['attention_analysis', 'classification_evaluation', 'processing_info', 'summary']
🔍 GUI除錯：classification_evaluation的鍵: ['no', 'similarity', 'keyword', 'self', 'comparison']
🔍 GUI除錯：找到機制結果: no
🔍 GUI除錯：找到機制結果: similarity
🔍 GUI除錯：找到機制結果: keyword
🔍 GUI除錯：找到機制結果: self
🔍 GUI除錯：最終classification_results的鍵: ['no', 'similarity', 'keyword', 'self']    
✅ 分析完成！最佳機制: 相似度注意力 (82.5400%) | 總耗時: 22.9317秒
🔍 GUI除錯：開始更新比對報告...
🔍 GUI除錯：選擇的機制: 相似度注意力
🔍 GUI除錯：classification_evaluation的鍵: ['no', 'similarity', 'keyword', 'self', 'comparison']
🔍 GUI除錯：找到機制結果: no
🔍 GUI除錯：找到機制結果: similarity
🔍 GUI除錯：找到機制結果: keyword
🔍 GUI除錯：找到機制結果: self
🔍 GUI除錯：比對報告中的classification_results鍵: ['no', 'similarity', 'keyword', 'self']
🔍 GUI除錯：檢查機制 no -> 無注意力
🔍 GUI除錯：檢查機制 similarity -> 相似度注意力
🔍 GUI除錯：找到匹配的機制結果