# BERTæƒ…æ„Ÿåˆ†æç³»çµ± Dockeréƒ¨ç½²æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æª”èªªæ˜å¦‚ä½•åœ¨Dockerç’°å¢ƒä¸­éƒ¨ç½²BERTæƒ…æ„Ÿåˆ†æç³»çµ±ï¼Œæ”¯æ´GPUåŠ é€Ÿå’ŒCPUé‹è¡Œæ¨¡å¼ã€‚

## ğŸ“‹ ç³»çµ±éœ€æ±‚

### GPUç‰ˆæœ¬
- Docker >= 20.10
- docker-compose >= 1.28
- NVIDIA Docker Runtime (nvidia-docker2)
- CUDA 11.8+
- GPUè¨˜æ†¶é«” >= 4GB

### CPUç‰ˆæœ¬
- Docker >= 20.10
- docker-compose >= 1.28
- è¨˜æ†¶é«” >= 8GB

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. å®‰è£Dockerå’ŒNVIDIA Runtimeï¼ˆGPUç‰ˆæœ¬ï¼‰

```bash
# Ubuntu/Debian
# å®‰è£Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å®‰è£NVIDIA Docker Runtime
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 2. éƒ¨ç½²ç³»çµ±

```bash
# ä¸‹è¼‰å°ˆæ¡ˆ
git clone <your-repo-url>
cd 2026_Thesis

# åŸ·è¡Œéƒ¨ç½²è…³æœ¬
chmod +x deploy.sh
./deploy.sh
```

### 3. ä½¿ç”¨ç³»çµ±

```bash
# æŸ¥çœ‹å®¹å™¨ç‹€æ…‹
docker-compose ps

# é€²å…¥å®¹å™¨ï¼ˆGPUç‰ˆæœ¬ï¼‰
docker-compose exec bert-analysis-gpu bash

# é€²å…¥å®¹å™¨ï¼ˆCPUç‰ˆæœ¬ï¼‰
docker-compose exec bert-analysis-cpu bash

# é‹è¡Œåˆ†æ
python Part05_Main.py --classify data.csv
```

## ğŸ“Š æœå‹™ç®¡ç†

### å•Ÿå‹•æœå‹™

```bash
# GPUç‰ˆæœ¬
docker-compose up -d bert-analysis-gpu

# CPUç‰ˆæœ¬
docker-compose up -d bert-analysis-cpu

# é–‹ç™¼ç’°å¢ƒ
docker-compose up -d bert-dev
```

### åœæ­¢æœå‹™

```bash
docker-compose down
```

### æŸ¥çœ‹æ—¥èªŒ

```bash
docker-compose logs -f bert-analysis-gpu
```

### é‡å»ºæ˜ åƒ

```bash
docker-compose build --no-cache
```

## ğŸ“ æ•¸æ“šå·é…ç½®

ç³»çµ±æœƒæ›è¼‰ä»¥ä¸‹ç›®éŒ„ï¼š

- `./data` â†’ `/app/data`ï¼šè¼¸å…¥æ•¸æ“š
- `./output` â†’ `/app/output`ï¼šåˆ†æçµæœ
- `./models` â†’ `/app/models`ï¼šæ¨¡å‹æ–‡ä»¶
- `./logs` â†’ `/app/logs`ï¼šæ—¥èªŒæ–‡ä»¶

## ğŸ® GPUä½¿ç”¨èªªæ˜

### æª¢æŸ¥GPUç‹€æ…‹

```bash
# åœ¨å®¹å™¨å…§
nvidia-smi

# æª¢æŸ¥PyTorch GPUæ”¯æ´
python -c "import torch; print(f'GPUå¯ç”¨: {torch.cuda.is_available()}')"
```

### GPUè¨˜æ†¶é«”ç®¡ç†

```bash
# è¨­ç½®GPUè¨˜æ†¶é«”é™åˆ¶
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

## ğŸ”§ å¸¸è¦‹å•é¡Œè§£æ±º

### 1. GPUä¸å¯ç”¨

```bash
# æª¢æŸ¥NVIDIA Driver
nvidia-smi

# æª¢æŸ¥Docker GPUæ”¯æ´
docker run --gpus all nvidia/cuda:11.8-base nvidia-smi
```

### 2. è¨˜æ†¶é«”ä¸è¶³

```bash
# æ¸…ç†Dockerç·©å­˜
docker system prune -a

# å¢åŠ swapç©ºé–“
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### 3. ç¶²è·¯å•é¡Œ

```bash
# ä½¿ç”¨åœ‹å…§é¡åƒ
export DOCKER_BUILDKIT=1
docker build --build-arg PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple/ .
```

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–

### GPUå„ªåŒ–

```bash
# è¨­ç½®ç’°å¢ƒè®Šæ•¸
export CUDA_VISIBLE_DEVICES=0
export TORCH_BACKENDS_CUDNN_BENCHMARK=true
export PYTHONPATH=/app:$PYTHONPATH
```

### å…§å­˜å„ªåŒ–

```bash
# é™åˆ¶è¨˜æ†¶é«”ä½¿ç”¨
docker-compose run --memory="8g" bert-analysis-gpu
```

## ğŸ” ç›£æ§å’Œè¨ºæ–·

### è³‡æºç›£æ§

```bash
# å¯¦æ™‚ç›£æ§
docker stats

# GPUç›£æ§
watch -n 1 nvidia-smi
```

### è¨ºæ–·å‘½ä»¤

```bash
# æª¢æŸ¥å®¹å™¨å¥åº·ç‹€æ…‹
docker-compose exec bert-analysis-gpu python -c "
import torch, transformers, sklearn, pandas
print('âœ… æ‰€æœ‰ä¾è³´æ­£å¸¸')
print(f'âœ… GPUå¯ç”¨: {torch.cuda.is_available()}')
"
```

## ğŸ“ æŠ€è¡“æ”¯æ´

å¦‚æœ‰å•é¡Œï¼Œè«‹æŸ¥çœ‹ï¼š

1. å®¹å™¨æ—¥èªŒï¼š`docker-compose logs -f`
2. ç³»çµ±ç‹€æ…‹ï¼š`docker-compose ps`
3. è³‡æºä½¿ç”¨ï¼š`docker stats`
4. GPUç‹€æ…‹ï¼š`nvidia-smi` 