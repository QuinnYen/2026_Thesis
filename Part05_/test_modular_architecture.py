#!/usr/bin/env python3
"""
æ¨¡çµ„åŒ–æ¶æ§‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ–°çš„ç·¨ç¢¼å™¨å’Œé¢å‘åˆ†é¡å™¨çµ„åˆ
"""

import os
import sys
import pandas as pd
import numpy as np
import time
from datetime import datetime

def test_basic_imports():
    """æ¸¬è©¦åŸºæœ¬å°å…¥"""
    print("ğŸ” æ¸¬è©¦åŸºæœ¬å°å…¥...")
    
    try:
        # æ¸¬è©¦åŸºç¤æ¥å£
        from modules.base_interfaces import BaseTextEncoder, BaseAspectClassifier, BasePipeline
        print("  âœ… åŸºç¤æ¥å£å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦å·¥å» é¡
        from modules.encoder_factory import EncoderFactory
        from modules.aspect_factory import AspectFactory
        print("  âœ… å·¥å» é¡å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦æ¨¡çµ„åŒ–æµæ°´ç·š
        from modules.modular_pipeline import ModularPipeline
        print("  âœ… æ¨¡çµ„åŒ–æµæ°´ç·šå°å…¥æˆåŠŸ")
        
        return True
    except ImportError as e:
        print(f"  âŒ å°å…¥å¤±æ•—: {e}")
        return False

def test_encoder_factory():
    """æ¸¬è©¦ç·¨ç¢¼å™¨å·¥å» """
    print("\nğŸ”§ æ¸¬è©¦ç·¨ç¢¼å™¨å·¥å» ...")
    
    try:
        from modules.encoder_factory import EncoderFactory
        
        # æ¸¬è©¦ç²å–å¯ç”¨ç·¨ç¢¼å™¨
        available_encoders = EncoderFactory.get_available_encoders()
        print(f"  ğŸ“‹ å¯ç”¨ç·¨ç¢¼å™¨: {available_encoders}")
        
        # æ¸¬è©¦ç·¨ç¢¼å™¨ä¿¡æ¯
        for encoder_type in available_encoders:
            info = EncoderFactory.get_encoder_info(encoder_type)
            print(f"  ğŸ“„ {encoder_type}: {info['name']} ({info.get('embedding_dim', 'N/A')}ç¶­)")
        
        return True
    except Exception as e:
        print(f"  âŒ ç·¨ç¢¼å™¨å·¥å» æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_aspect_factory():
    """æ¸¬è©¦é¢å‘åˆ†é¡å™¨å·¥å» """
    print("\nğŸ¯ æ¸¬è©¦é¢å‘åˆ†é¡å™¨å·¥å» ...")
    
    try:
        from modules.aspect_factory import AspectFactory
        
        # æ¸¬è©¦ç²å–å¯ç”¨åˆ†é¡å™¨
        available_classifiers = AspectFactory.get_available_classifiers()
        print(f"  ğŸ“‹ å¯ç”¨åˆ†é¡å™¨: {available_classifiers}")
        
        # æ¸¬è©¦åˆ†é¡å™¨ä¿¡æ¯
        for classifier_type in available_classifiers:
            info = AspectFactory.get_classifier_info(classifier_type)
            print(f"  ğŸ“„ {classifier_type}: {info['name']}")
            print(f"     - å„ªé»: {', '.join(info.get('advantages', []))}")
            print(f"     - é©ç”¨å ´æ™¯: {', '.join(info.get('suitable_for', []))}")
        
        return True
    except Exception as e:
        print(f"  âŒ é¢å‘åˆ†é¡å™¨å·¥å» æ¸¬è©¦å¤±æ•—: {e}")
        return False

def create_sample_data():
    """å‰µå»ºæ¸¬è©¦æ•¸æ“š"""
    print("\nğŸ“ å‰µå»ºæ¸¬è©¦æ•¸æ“š...")
    
    sample_texts = [
        "This movie is absolutely fantastic! Great acting and storyline.",
        "The product quality is terrible, very disappointed.",
        "Average restaurant, nothing special but decent food.",
        "Excellent service and amazing food, highly recommended!",
        "Poor customer support, will not buy again.",
        "The plot was confusing but the visuals were stunning.",
        "Good value for money, satisfied with the purchase.",
        "Outstanding performance by all actors in this film.",
        "Food was cold and tasteless, worst experience ever.",
        "Beautiful cinematography and excellent direction."
    ]
    
    sentiments = ['positive', 'negative', 'neutral', 'positive', 'negative',
                 'neutral', 'positive', 'positive', 'negative', 'positive']
    
    df = pd.DataFrame({
        'text': sample_texts,
        'sentiment': sentiments
    })
    
    print(f"  âœ… å‰µå»ºäº† {len(df)} æ¢æ¸¬è©¦æ•¸æ“š")
    return df

def test_individual_encoders():
    """æ¸¬è©¦å€‹åˆ¥ç·¨ç¢¼å™¨"""
    print("\nğŸ§ª æ¸¬è©¦å€‹åˆ¥ç·¨ç¢¼å™¨...")
    
    try:
        from modules.encoder_factory import EncoderFactory
        
        # å‰µå»ºæ¸¬è©¦æ–‡æœ¬
        test_texts = ["This is a test sentence.", "Another test sentence for encoding."]
        
        # æ¸¬è©¦æ¯å€‹ç·¨ç¢¼å™¨ï¼ˆé™¤äº†éœ€è¦ç‰¹æ®Šè¨­ç½®çš„ï¼‰
        test_encoders = ['bert', 'cnn']  # ç°¡åŒ–æ¸¬è©¦ï¼Œåªæ¸¬è©¦å®¹æ˜“é…ç½®çš„ç·¨ç¢¼å™¨
        
        for encoder_type in test_encoders:
            try:
                print(f"  ğŸ”§ æ¸¬è©¦ {encoder_type.upper()} ç·¨ç¢¼å™¨...")
                
                # å‰µå»ºç·¨ç¢¼å™¨
                encoder = EncoderFactory.create_encoder(encoder_type, config={'batch_size': 2})
                
                # æ¸¬è©¦ç·¨ç¢¼
                start_time = time.time()
                embeddings = encoder.encode(test_texts)
                encoding_time = time.time() - start_time
                
                print(f"    âœ… ç·¨ç¢¼æˆåŠŸ: å½¢ç‹€ {embeddings.shape}, è€—æ™‚ {encoding_time:.2f}ç§’")
                print(f"    ğŸ“ åµŒå…¥ç¶­åº¦: {encoder.get_embedding_dim()}")
                
            except Exception as e:
                print(f"    âš ï¸  {encoder_type} ç·¨ç¢¼å™¨æ¸¬è©¦è·³é: {e}")
        
        return True
    except Exception as e:
        print(f"  âŒ ç·¨ç¢¼å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_individual_aspect_classifiers():
    """æ¸¬è©¦å€‹åˆ¥é¢å‘åˆ†é¡å™¨"""
    print("\nğŸ¯ æ¸¬è©¦å€‹åˆ¥é¢å‘åˆ†é¡å™¨...")
    
    try:
        from modules.aspect_factory import AspectFactory
        
        # å‰µå»ºå‡çš„åµŒå…¥å‘é‡å’Œå…ƒæ•¸æ“š
        embeddings = np.random.randn(5, 768)  # 5å€‹æ¨£æœ¬ï¼Œ768ç¶­
        metadata = pd.DataFrame({
            'text': ["Test sentence " + str(i) for i in range(5)],
            'sentiment': ['positive', 'negative', 'neutral', 'positive', 'negative']
        })
        
        # æ¸¬è©¦æ¯å€‹åˆ†é¡å™¨ï¼ˆé™¤äº†éœ€è¦ç‰¹æ®Šä¾è³´çš„ï¼‰
        test_classifiers = ['default', 'lda', 'nmf']  # ç°¡åŒ–æ¸¬è©¦
        
        for classifier_type in test_classifiers:
            try:
                print(f"  ğŸ”§ æ¸¬è©¦ {classifier_type.upper()} åˆ†é¡å™¨...")
                
                # å‰µå»ºåˆ†é¡å™¨
                classifier = AspectFactory.create_classifier(classifier_type)
                
                # æ¸¬è©¦åˆ†é¡
                start_time = time.time()
                aspect_vectors, results = classifier.fit_transform(embeddings, metadata)
                classification_time = time.time() - start_time
                
                aspect_names = classifier.get_aspect_names()
                
                print(f"    âœ… åˆ†é¡æˆåŠŸ: {len(aspect_names)} å€‹é¢å‘, è€—æ™‚ {classification_time:.2f}ç§’")
                print(f"    ğŸ“Š é¢å‘å‘é‡å½¢ç‹€: {aspect_vectors.shape}")
                print(f"    ğŸ·ï¸  é¢å‘åç¨±: {aspect_names[:3]}...")  # åªé¡¯ç¤ºå‰3å€‹
                
            except Exception as e:
                print(f"    âš ï¸  {classifier_type} åˆ†é¡å™¨æ¸¬è©¦è·³é: {e}")
        
        return True
    except Exception as e:
        print(f"  âŒ é¢å‘åˆ†é¡å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_modular_pipeline():
    """æ¸¬è©¦æ¨¡çµ„åŒ–æµæ°´ç·š"""
    print("\nğŸš€ æ¸¬è©¦æ¨¡çµ„åŒ–æµæ°´ç·š...")
    
    try:
        from modules.modular_pipeline import ModularPipeline
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        df = create_sample_data()
        
        # æ¸¬è©¦çµ„åˆ
        test_combinations = [
            ('bert', 'default'),
            ('cnn', 'nmf')
        ]
        
        for encoder_type, aspect_type in test_combinations:
            try:
                print(f"  ğŸ”§ æ¸¬è©¦çµ„åˆ: {encoder_type.upper()} + {aspect_type.upper()}")
                
                # å‰µå»ºæµæ°´ç·š
                pipeline = ModularPipeline(
                    encoder_type=encoder_type,
                    aspect_type=aspect_type,
                    encoder_config={'batch_size': 4},
                    aspect_config={'n_topics': 3}
                )
                
                # åŸ·è¡Œæµæ°´ç·š
                start_time = time.time()
                results = pipeline.process(df)
                processing_time = time.time() - start_time
                
                print(f"    âœ… æµæ°´ç·šæˆåŠŸ: è€—æ™‚ {processing_time:.2f}ç§’")
                print(f"    ğŸ“Š è™•ç†äº† {len(df)} æ¢è¨˜éŒ„")
                print(f"    ğŸ“ åµŒå…¥ç¶­åº¦: {pipeline.text_encoder.get_embedding_dim()}")
                print(f"    ğŸ¯ ç™¼ç¾é¢å‘: {len(pipeline.aspect_classifier.get_aspect_names())}")
                
            except Exception as e:
                print(f"    âš ï¸  çµ„åˆ {encoder_type}+{aspect_type} æ¸¬è©¦è·³é: {e}")
        
        return True
    except Exception as e:
        print(f"  âŒ æ¨¡çµ„åŒ–æµæ°´ç·šæ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_pipeline_combinations():
    """æ¸¬è©¦å¯ç”¨çµ„åˆ"""
    print("\nğŸ”„ æ¸¬è©¦æµæ°´ç·šçµ„åˆ...")
    
    try:
        from modules.modular_pipeline import ModularPipeline
        
        # å‰µå»ºæµæ°´ç·šå¯¦ä¾‹ä¾†ç²å–å¯ç”¨çµ„åˆ
        temp_pipeline = ModularPipeline('bert', 'default')
        combinations = temp_pipeline.get_available_combinations()
        
        print(f"  ğŸ“‹ å¯ç”¨ç·¨ç¢¼å™¨: {combinations['encoders']['available']}")
        print(f"  ğŸ“‹ å¯ç”¨åˆ†é¡å™¨: {combinations['aspect_classifiers']['available']}")
        
        print("\n  ğŸ¯ æ¨è–¦çµ„åˆ:")
        for combo in combinations['recommended_combinations']:
            print(f"    â€¢ {combo['encoder'].upper()} + {combo['aspect_classifier'].upper()}: {combo['scenario']}")
        
        return True
    except Exception as e:
        print(f"  âŒ çµ„åˆæ¸¬è©¦å¤±æ•—: {e}")
        return False

def run_all_tests():
    """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("ğŸ§ª é–‹å§‹æ¨¡çµ„åŒ–æ¶æ§‹æ¸¬è©¦\n")
    print(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    test_results = []
    
    # é‹è¡Œå„é …æ¸¬è©¦
    tests = [
        ("åŸºæœ¬å°å…¥", test_basic_imports),
        ("ç·¨ç¢¼å™¨å·¥å» ", test_encoder_factory),
        ("é¢å‘åˆ†é¡å™¨å·¥å» ", test_aspect_factory),
        ("å€‹åˆ¥ç·¨ç¢¼å™¨", test_individual_encoders),
        ("å€‹åˆ¥é¢å‘åˆ†é¡å™¨", test_individual_aspect_classifiers),
        ("æ¨¡çµ„åŒ–æµæ°´ç·š", test_modular_pipeline),
        ("æµæ°´ç·šçµ„åˆ", test_pipeline_combinations)
    ]
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print(f"\nâŒ {test_name} æ¸¬è©¦ç™¼ç”Ÿæœªæ•ç²çš„éŒ¯èª¤: {e}")
            test_results.append((test_name, False))
    
    # ç¸½çµçµæœ
    print("\n" + "=" * 60)
    print("ğŸ æ¸¬è©¦çµæœç¸½çµ:")
    
    passed = 0
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nç¸½è¨ˆ: {passed}/{len(test_results)} æ¸¬è©¦é€šé")
    
    if passed == len(test_results):
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ¨¡çµ„åŒ–æ¶æ§‹é‹è¡Œæ­£å¸¸ã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œçµ„ä»¶ã€‚")
        return False

if __name__ == "__main__":
    # æ·»åŠ æ¨¡çµ„è·¯å¾‘
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # é‹è¡Œæ¸¬è©¦
    success = run_all_tests()
    
    # é€€å‡ºä»£ç¢¼
    sys.exit(0 if success else 1)