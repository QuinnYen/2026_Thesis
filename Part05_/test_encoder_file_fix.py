#!/usr/bin/env python3
"""
ç·¨ç¢¼å™¨æª”æ¡ˆæª¢æ¸¬ä¿®å¾©é©—è­‰è…³æœ¬
é©—è­‰åˆ†é¡è©•ä¼°éšæ®µèƒ½æ­£ç¢ºæ‰¾åˆ°ä¸åŒç·¨ç¢¼å™¨çš„å‘é‡æª”æ¡ˆ
"""

import os
import sys
import ast

def analyze_main_program_fixes():
    """åˆ†æä¸»ç¨‹å¼çš„ä¿®å¾©æƒ…æ³"""
    print("ğŸ” åˆ†æä¸»ç¨‹å¼ä¿®å¾©...")
    
    file_path = 'Part05_Main.py'
    
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
        return False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥ä¿®å¾©é …ç›®
    checks = [
        ("ç§»é™¤ç¡¬ç·¨ç¢¼BERTè·¯å¾‘", "02_bert_embeddings.npy" not in content),
        ("ä½¿ç”¨é€šç”¨æª”æ¡ˆæª¢æ¸¬", "temp_processor._find_existing_embeddings" in content),
        ("æ”¯æ´å¤šç¨®ç·¨ç¢¼å™¨", "encoder_type.upper()" in content),
        ("AttentionProcessoråˆå§‹åŒ–åŒ…å«ç·¨ç¢¼å™¨é¡å‹", "AttentionProcessor(output_dir=output_dir, encoder_type=encoder_type)" in content),
        ("åˆ†é¡å™¨åˆå§‹åŒ–åŒ…å«ç·¨ç¢¼å™¨é¡å‹", "SentimentClassifier(output_dir=output_dir, encoder_type=encoder_type)" in content),
        ("å‹•æ…‹ç·¨ç¢¼å™¨é¸æ“‡", "if encoder_type == 'bert':" in content),
        ("éŒ¯èª¤å›é€€æ©Ÿåˆ¶", "å›é€€ä½¿ç”¨BERT" in content),
    ]
    
    passed = 0
    for check_name, condition in checks:
        if condition:
            print(f"  âœ… {check_name}")
            passed += 1
        else:
            print(f"  âŒ {check_name}")
    
    print(f"  ğŸ“Š ä¸»ç¨‹å¼ä¿®å¾©æª¢æŸ¥: {passed}/{len(checks)} é€šé")
    return passed >= len(checks) - 1  # å…è¨±1å€‹å¤±æ•—

def analyze_sentiment_classifier_fixes():
    """åˆ†ææƒ…æ„Ÿåˆ†é¡å™¨çš„ä¿®å¾©æƒ…æ³"""
    print("\nğŸ” åˆ†ææƒ…æ„Ÿåˆ†é¡å™¨ä¿®å¾©...")
    
    file_path = 'modules/sentiment_classifier.py'
    
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
        return False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    checks = [
        ("æ·»åŠ ç·¨ç¢¼å™¨é¡å‹åƒæ•¸", "encoder_type: str = 'bert'" in content),
        ("ç§»é™¤ç¡¬ç·¨ç¢¼BERTè·¯å¾‘", content.count("02_bert_embeddings.npy") <= 1),  # å…è¨±1å€‹æ®˜ç•™
        ("ä½¿ç”¨é€šç”¨æª”æ¡ˆæª¢æ¸¬", "AttentionProcessor(output_dir=self.output_dir, encoder_type=self.encoder_type)" in content),
        ("å‹•æ…‹ç·¨ç¢¼å™¨æ”¯æ´", "self.encoder_type.upper()" in content),
        ("éŒ¯èª¤è™•ç†æ”¹é€²", "è¼‰å…¥.*åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤" in content),
        ("æª”æ¡ˆä¾†æºè¨˜éŒ„", "æª”æ¡ˆä¾†æº:" in content),
    ]
    
    passed = 0
    for check_name, condition in checks:
        if condition:
            print(f"  âœ… {check_name}")
            passed += 1
        else:
            print(f"  âŒ {check_name}")
    
    print(f"  ğŸ“Š æƒ…æ„Ÿåˆ†é¡å™¨ä¿®å¾©æª¢æŸ¥: {passed}/{len(checks)} é€šé")
    return passed >= len(checks) - 1

def analyze_attention_processor_support():
    """åˆ†ææ³¨æ„åŠ›è™•ç†å™¨çš„æ”¯æ´æƒ…æ³"""
    print("\nğŸ” åˆ†ææ³¨æ„åŠ›è™•ç†å™¨æ”¯æ´...")
    
    file_path = 'modules/attention_processor.py'
    
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
        return False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    checks = [
        ("å¤šç·¨ç¢¼å™¨æª”æ¡ˆæª¢æ¸¬", "_find_existing_embeddings" in content and "encoder_type" in content),
        ("æª”æ¡ˆé©—è­‰æ©Ÿåˆ¶", "_validate_embeddings_file" in content),
        ("å¤šç¨®ç›®éŒ„çµæ§‹æ”¯æ´", "02_encoding" in content and "02_bert_encoding" in content),
        ("å¤šç¨®æª”æ¡ˆæ ¼å¼æ”¯æ´", "02_{encoder_type}_embeddings.npy" in content),
        ("å‘å¾Œç›¸å®¹æ€§", "èˆŠçš„BERTå‘½å" in content),
        ("è©³ç´°æ—¥èªŒè¨˜éŒ„", "logger.info" in content),
    ]
    
    passed = 0
    for check_name, condition in checks:
        if condition:
            print(f"  âœ… {check_name}")
            passed += 1
        else:
            print(f"  âŒ {check_name}")
    
    print(f"  ğŸ“Š æ³¨æ„åŠ›è™•ç†å™¨æ”¯æ´æª¢æŸ¥: {passed}/{len(checks)} é€šé")
    return passed == len(checks)

def check_syntax_correctness():
    """æª¢æŸ¥èªæ³•æ­£ç¢ºæ€§"""
    print("\nğŸ”§ æª¢æŸ¥èªæ³•æ­£ç¢ºæ€§...")
    
    files_to_check = [
        'Part05_Main.py',
        'modules/attention_processor.py',
        'modules/sentiment_classifier.py'
    ]
    
    all_ok = True
    
    for file_path in files_to_check:
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()
                ast.parse(code)
                print(f"  âœ… {file_path} èªæ³•æ­£ç¢º")
            except SyntaxError as e:
                print(f"  âŒ {file_path} èªæ³•éŒ¯èª¤: {e}")
                all_ok = False
            except Exception as e:
                print(f"  âš ï¸ {file_path} æª¢æŸ¥éŒ¯èª¤: {e}")
        else:
            print(f"  âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
    
    return all_ok

def analyze_file_detection_improvement():
    """åˆ†ææª”æ¡ˆæª¢æ¸¬æ”¹é€²æƒ…æ³"""
    print("\nğŸ“‚ åˆ†ææª”æ¡ˆæª¢æ¸¬æ”¹é€²...")
    
    improvements = [
        ("æ”¯æ´5ç¨®ç·¨ç¢¼å™¨", "BERT, GPT, T5, CNN, ELMo"),
        ("å¤šç¨®æª”æ¡ˆå‘½åæ¨¡å¼", "02_{type}_embeddings.npy, {type}_embeddings.npy, embeddings.npy"),
        ("å…©ç¨®ç›®éŒ„çµæ§‹", "02_encoding/, 02_bert_encoding/"),
        ("æ™ºæ…§æª”æ¡ˆé©—è­‰", "æª”æ¡ˆåæª¢æŸ¥ã€è³‡è¨Šæª”æ¡ˆé©—è­‰ã€ç›®éŒ„æ¨æ–·"),
        ("éŒ¯èª¤è™•ç†æ©Ÿåˆ¶", "æ‰¾ä¸åˆ°æª”æ¡ˆæ™‚çš„å›é€€ç­–ç•¥"),
        ("å‘å¾Œç›¸å®¹æ€§", "å®Œå…¨æ”¯æ´èˆŠBERTæª”æ¡ˆæ ¼å¼"),
        ("è©³ç´°æ—¥èªŒè¨˜éŒ„", "æª”æ¡ˆä¾†æºå’Œè¼‰å…¥ç‹€æ…‹è¨˜éŒ„"),
    ]
    
    for improvement, description in improvements:
        print(f"  âœ… {improvement}: {description}")
    
    return True

def simulate_file_detection_scenarios():
    """æ¨¡æ“¬æª”æ¡ˆæª¢æ¸¬å ´æ™¯"""
    print("\nğŸ­ æ¨¡æ“¬æª”æ¡ˆæª¢æ¸¬å ´æ™¯...")
    
    scenarios = [
        {
            "name": "BERTæª”æ¡ˆæª¢æ¸¬",
            "encoder": "bert",
            "files": ["02_bert_embeddings.npy", "02_bert_encoding/"],
            "expected": "âœ… æ‡‰è©²æ‰¾åˆ°èˆŠæ ¼å¼BERTæª”æ¡ˆ"
        },
        {
            "name": "GPTæª”æ¡ˆæª¢æ¸¬", 
            "encoder": "gpt",
            "files": ["02_gpt_embeddings.npy", "02_encoding/"],
            "expected": "âœ… æ‡‰è©²æ‰¾åˆ°æ–°æ ¼å¼GPTæª”æ¡ˆ"
        },
        {
            "name": "æ··åˆæª”æ¡ˆç’°å¢ƒ",
            "encoder": "t5",
            "files": ["02_bert_embeddings.npy", "02_t5_embeddings.npy"],
            "expected": "âœ… æ‡‰è©²é¸æ“‡æ­£ç¢ºçš„T5æª”æ¡ˆ"
        },
        {
            "name": "æ‰¾ä¸åˆ°æª”æ¡ˆ",
            "encoder": "elmo",
            "files": ["ç„¡ç›¸é—œæª”æ¡ˆ"],
            "expected": "âš ï¸ æ‡‰è©²å›é€€åˆ°é‡æ–°ç”Ÿæˆ"
        }
    ]
    
    for scenario in scenarios:
        print(f"  ğŸ¯ {scenario['name']}:")
        print(f"     ç·¨ç¢¼å™¨: {scenario['encoder'].upper()}")
        print(f"     æª”æ¡ˆç’°å¢ƒ: {', '.join(scenario['files'])}")
        print(f"     é æœŸçµæœ: {scenario['expected']}")
    
    return True

def main():
    """ä¸»é©—è­‰å‡½æ•¸"""
    print("ğŸš€ ç·¨ç¢¼å™¨æª”æ¡ˆæª¢æ¸¬ä¿®å¾©é©—è­‰")
    print("=" * 60)
    
    tests = [
        ("èªæ³•æ­£ç¢ºæ€§", check_syntax_correctness),
        ("ä¸»ç¨‹å¼ä¿®å¾©", analyze_main_program_fixes),
        ("æƒ…æ„Ÿåˆ†é¡å™¨ä¿®å¾©", analyze_sentiment_classifier_fixes),
        ("æ³¨æ„åŠ›è™•ç†å™¨æ”¯æ´", analyze_attention_processor_support),
        ("æª”æ¡ˆæª¢æ¸¬æ”¹é€²", analyze_file_detection_improvement),
        ("å ´æ™¯æ¨¡æ“¬", simulate_file_detection_scenarios),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name} é€šé")
            else:
                print(f"âŒ {test_name} å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name} ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    print(f"\n{'='*60}")
    print(f"ğŸ é©—è­‰å®Œæˆ: {passed}/{total} æª¢æŸ¥é€šé")
    
    if passed >= total - 1:  # å…è¨±1å€‹å¤±æ•—
        print("ğŸ‰ ä¿®å¾©æˆåŠŸï¼ç³»çµ±ç¾åœ¨èƒ½æ­£ç¢ºæ‰¾åˆ°ä¸åŒç·¨ç¢¼å™¨çš„æª”æ¡ˆ")
        print("\nğŸ’¡ ä¸»è¦æ”¹é€²:")
        print("  â€¢ ç§»é™¤äº†æ‰€æœ‰ç¡¬ç·¨ç¢¼çš„BERTæª”æ¡ˆè·¯å¾‘")
        print("  â€¢ ä½¿ç”¨çµ±ä¸€çš„æª”æ¡ˆæª¢æ¸¬é‚è¼¯")
        print("  â€¢ æ”¯æ´å¤šç¨®ç·¨ç¢¼å™¨å’Œæª”æ¡ˆæ ¼å¼")
        print("  â€¢ å®Œå–„çš„éŒ¯èª¤è™•ç†å’Œå›é€€æ©Ÿåˆ¶")
        print("\nğŸ”§ ä½¿ç”¨æ–¹å¼:")
        print("  1. é¸æ“‡ä»»ä½•ç·¨ç¢¼å™¨é¡å‹ï¼ˆBERT/GPT/T5/CNN/ELMoï¼‰")
        print("  2. é‹è¡Œæ¨¡çµ„åŒ–æµæ°´ç·šç”Ÿæˆæª”æ¡ˆ")
        print("  3. åŸ·è¡Œæ³¨æ„åŠ›æ©Ÿåˆ¶æ¸¬è©¦")
        print("  4. ç³»çµ±è‡ªå‹•æ‰¾åˆ°å°æ‡‰çš„ç·¨ç¢¼å™¨æª”æ¡ˆ")
        print("\nğŸ“ æŠ€è¡“ç´°ç¯€:")
        print("  â€¢ æª”æ¡ˆæª¢æ¸¬å„ªå…ˆé †åºï¼šæ–°æ ¼å¼ â†’ èˆŠæ ¼å¼ â†’ é€šç”¨æ ¼å¼")
        print("  â€¢ ç›®éŒ„æœå°‹ç¯„åœï¼šç•¶å‰run â†’ æ‰€æœ‰run â†’ ç›¸é„°ç›®éŒ„")
        print("  â€¢ é©—è­‰æ©Ÿåˆ¶ï¼šæª”æ¡ˆå â†’ è³‡è¨Šæª”æ¡ˆ â†’ ç›®éŒ„çµæ§‹")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æª¢æŸ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œä¿®å¾©")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)