#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒ…æ„Ÿåˆ†é¡å™¨æ¨¡çµ„ - åŸºæ–¼æ³¨æ„åŠ›æ©Ÿåˆ¶ç‰¹å¾µçš„æƒ…æ„Ÿåˆ†é¡
"""

import numpy as np
import pandas as pd
import logging
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import GaussianNB
from tqdm import tqdm
import joblib
import os
import time
import torch
from typing import Dict, Any, Tuple, Optional, List

logger = logging.getLogger(__name__)

class SentimentClassifier:
    """åŸºæ–¼æ³¨æ„åŠ›æ©Ÿåˆ¶ç‰¹å¾µçš„æƒ…æ„Ÿåˆ†é¡å™¨"""
    
    def __init__(self, output_dir: Optional[str] = None, encoder_type: str = 'bert'):
        """
        åˆå§‹åŒ–æƒ…æ„Ÿåˆ†é¡å™¨
        
        Args:
            output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘
            encoder_type: ç·¨ç¢¼å™¨é¡å‹ (bert, gpt, t5, cnn, elmo)
        """
        self.output_dir = output_dir
        self.encoder_type = encoder_type
        self.model = None
        self.label_encoder = LabelEncoder()
        self.feature_vectors = None
        self.labels = None
        self.model_type = 'xgboost'  # ä¿®æ”¹ï¼šé è¨­ä½¿ç”¨XGBoostï¼ˆé«˜æº–ç¢ºç‡èˆ‡æ€§èƒ½ï¼‰
        
        # è‡ªå‹•åµæ¸¬GPU/CPUç’°å¢ƒ
        self.device_info = self._detect_compute_environment()
        logger.debug(f"è¨ˆç®—ç’°å¢ƒ: {self.device_info['description']}")
        
        # æ”¯æŒçš„æ¨¡å‹é¡å‹ - å„ªåŒ–é…ç½®
        self.available_models = self._init_models()
        
        logger.info("æƒ…æ„Ÿåˆ†é¡å™¨å·²åˆå§‹åŒ–")
        logger.debug(f"å¯ç”¨åˆ†é¡å™¨: {list(self.available_models.keys())}")
    
    def _detect_compute_environment(self) -> Dict[str, Any]:
        """è‡ªå‹•åµæ¸¬è¨ˆç®—ç’°å¢ƒï¼ˆGPU/CPUï¼‰"""
        device_info = {
            'has_gpu': False,
            'gpu_name': None,
            'gpu_memory': None,
            'cuda_available': False,
            'device': 'cpu',
            'description': 'CPU Only'
        }
        
        try:
            # æª¢æ¸¬CUDAå’ŒGPU
            if torch.cuda.is_available():
                device_info['cuda_available'] = True
                device_info['has_gpu'] = True
                device_info['device'] = 'cuda'
                device_info['gpu_name'] = torch.cuda.get_device_name(0)
                device_info['gpu_memory'] = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
                device_info['description'] = f"GPU: {device_info['gpu_name']} ({device_info['gpu_memory']:.1f}GB)"
                logger.debug(f"æª¢æ¸¬åˆ°GPU: {device_info['gpu_name']}")
            else:
                logger.debug("æœªæª¢æ¸¬åˆ°CUDA GPUï¼Œä½¿ç”¨CPUæ¨¡å¼")
                
        except Exception as e:
            logger.warning(f"GPUæª¢æ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            
        return device_info
    
    def _init_models(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–å¯ç”¨çš„æ¨¡å‹"""
        models = {
            'logistic_regression': LogisticRegression(
                random_state=42, 
                max_iter=1000, 
                C=1.0,
                n_jobs=-1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
            ),
            'random_forest': RandomForestClassifier(
                n_estimators=100, 
                random_state=42,
                n_jobs=-1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
            ),
            'svm_linear': SVC(
                kernel='linear', 
                C=1.0, 
                random_state=42, 
                probability=True
            ),
            'naive_bayes': GaussianNB()
        }
        
        # å˜—è©¦è¼‰å…¥XGBoost
        try:
            import xgboost as xgb
            
            # æª¢æŸ¥XGBoostç‰ˆæœ¬ä¸¦è¨˜éŒ„
            xgb_version = xgb.__version__
            logger.debug(f"æª¢æ¸¬åˆ°XGBoostç‰ˆæœ¬: {xgb_version}")
            
            # æª¢æŸ¥æ˜¯å¦ç‚º2.0.0+ç‰ˆæœ¬ï¼ˆä½¿ç”¨æ–°åƒæ•¸ï¼‰
            xgb_major_version = int(xgb_version.split('.')[0])
            is_new_xgb = xgb_major_version >= 2
            
            if is_new_xgb:
                logger.debug("ä½¿ç”¨XGBoost 2.0.0+æ–°ç‰ˆæœ¬åƒæ•¸é…ç½®")
            else:
                logger.debug("ä½¿ç”¨XGBoost 1.xç‰ˆæœ¬åƒæ•¸é…ç½®")
            
            # GPUåŠ é€Ÿé…ç½® - æ ¹æ“šç‰ˆæœ¬å’ŒGPUå¯ç”¨æ€§é…ç½®åƒæ•¸
            if self.device_info['has_gpu']:
                if is_new_xgb:
                    # XGBoost 2.0.0+ GPUé…ç½® - ä½¿ç”¨æ–°åƒæ•¸
                    xgb_params = {
                        'tree_method': 'hist',      # æ–°ç‰ˆæœ¬çµ±ä¸€ä½¿ç”¨ 'hist'
                        'device': 'cuda',           # ä½¿ç”¨ 'device' æ›¿ä»£ 'gpu_id'
                        'n_estimators': 100,
                        'max_depth': 6,
                        'learning_rate': 0.1,
                        'subsample': 0.8,
                        'colsample_bytree': 0.8,
                        'random_state': 42,
                        'n_jobs': -1
                    }
                    logger.debug("XGBoosté…ç½®ç‚ºGPUæ¨¡å¼ (v2.0+: device='cuda', tree_method='hist')")
                else:
                    # XGBoost 1.x GPUé…ç½® - ä½¿ç”¨èˆŠåƒæ•¸
                    xgb_params = {
                        'tree_method': 'gpu_hist',  # èˆŠç‰ˆæœ¬ä½¿ç”¨ 'gpu_hist'
                        'gpu_id': 0,                # èˆŠç‰ˆæœ¬ä½¿ç”¨ 'gpu_id'
                        'n_estimators': 100,
                        'max_depth': 6,
                        'learning_rate': 0.1,
                        'subsample': 0.8,
                        'colsample_bytree': 0.8,
                        'random_state': 42,
                        'n_jobs': -1
                    }
                    logger.debug("XGBoosté…ç½®ç‚ºGPUæ¨¡å¼ (v1.x: gpu_id=0, tree_method='gpu_hist')")
                
                logger.info("ğŸš€ GPUåŠ é€Ÿå·²å•Ÿç”¨")
            else:
                # CPUé…ç½®ï¼ˆå…©å€‹ç‰ˆæœ¬éƒ½ä¸€æ¨£ï¼‰
                xgb_params = {
                    'tree_method': 'hist',      # CPUä¸Šæœ€å¿«çš„æ–¹æ³•
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'random_state': 42,
                    'n_jobs': -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
                }
                if is_new_xgb:
                    xgb_params['device'] = 'cpu'  # æ–°ç‰ˆæœ¬æ˜ç¢ºæŒ‡å®šCPUè¨­å‚™
                    logger.info("XGBoosté…ç½®ç‚ºCPUæ¨¡å¼ (v2.0+: device='cpu')")
                else:
                    logger.info("XGBoosté…ç½®ç‚ºCPUæ¨¡å¼ (v1.x: tree_method='hist')")
            
            models['xgboost'] = xgb.XGBClassifier(**xgb_params)
            logger.info("XGBoostå·²æˆåŠŸè¼‰å…¥ä¸¦é…ç½®")
            
        except ImportError:
            logger.warning("XGBoostæœªå®‰è£ï¼Œè«‹ä½¿ç”¨ 'pip install xgboost' å®‰è£")
        except Exception as e:
            logger.error(f"XGBooståˆå§‹åŒ–å¤±æ•—: {str(e)}")
        
        return models
    
    def get_available_models(self) -> List[str]:
        """ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return list(self.available_models.keys())
    
    def get_device_info(self) -> Dict[str, Any]:
        """ç²å–è¨­å‚™ä¿¡æ¯"""
        return self.device_info.copy()
    
    def _get_naive_bayes_classifier(self):
        """ç²å–Naive Bayesåˆ†é¡å™¨"""
        return GaussianNB()
    
    def prepare_features(self, aspect_vectors: Dict, metadata: pd.DataFrame, 
                        original_embeddings: np.ndarray = None, 
                        fused_features: np.ndarray = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        æº–å‚™åˆ†é¡ç‰¹å¾µï¼Œæ”¯æ´èåˆç‰¹å¾µå’ŒåŸå§‹ç‰¹å¾µ
        
        Args:
            aspect_vectors: é¢å‘ç‰¹å¾µå‘é‡å­—å…¸
            metadata: åŒ…å«çœŸå¯¦æ¨™ç±¤çš„å…ƒæ•¸æ“š
            original_embeddings: åŸå§‹BERTåµŒå…¥å‘é‡
            fused_features: èåˆå¾Œçš„ç‰¹å¾µå‘é‡ï¼ˆæ–°æ¶æ§‹ï¼‰
            
        Returns:
            features: ç‰¹å¾µçŸ©é™£
            labels: æ¨™ç±¤æ•¸çµ„
        """
        start_time = time.time()
        logger.info("é–‹å§‹æº–å‚™åˆ†é¡ç‰¹å¾µ...")
        
        # å„ªå…ˆä½¿ç”¨æ•¸å€¼åŒ–æƒ…æ„Ÿæ¨™ç±¤
        if 'sentiment_numeric' in metadata.columns:
            logger.info("ä½¿ç”¨æ•¸å€¼åŒ–æƒ…æ„Ÿæ¨™ç±¤ (sentiment_numeric)")
            sentiments = metadata['sentiment_numeric'].values
            # æ•¸å€¼åŒ–æ¨™ç±¤å·²ç¶“æ˜¯ç·¨ç¢¼å½¢å¼ï¼Œç›´æ¥ä½¿ç”¨
            encoded_labels = sentiments.astype(int)
            # è¨­å®šæ¨™ç±¤ç·¨ç¢¼å™¨çš„é¡åˆ¥ï¼ˆ0:è² é¢, 1:ä¸­æ€§, 2:æ­£é¢ï¼‰
            self.label_encoder.classes_ = np.array([0, 1, 2])
        elif 'sentiment' not in metadata.columns:
            if 'review_stars' in metadata.columns:
                logger.info("æœªæ‰¾åˆ° 'sentiment' æ¬„ä½ï¼Œæ ¹æ“š 'review_stars' ç”Ÿæˆæ•¸å€¼åŒ–æƒ…æ„Ÿæ¨™ç±¤...")
                # æ ¹æ“šè©•åˆ†ç”Ÿæˆæ•¸å€¼åŒ–æƒ…æ„Ÿæ¨™ç±¤ï¼š1-2æ˜Ÿ=0(è² é¢), 3æ˜Ÿ=1(ä¸­æ€§), 4-5æ˜Ÿ=2(æ­£é¢)
                def map_stars_to_numeric(stars):
                    if stars <= 2:
                        return 0  # è² é¢
                    elif stars == 3:
                        return 1  # ä¸­æ€§
                    else:
                        return 2  # æ­£é¢
                
                sentiments = metadata['review_stars'].apply(map_stars_to_numeric).values
                encoded_labels = sentiments.astype(int)
                self.label_encoder.classes_ = np.array([0, 1, 2])
                logger.info(f"ç”Ÿæˆçš„æ•¸å€¼åŒ–æƒ…æ„Ÿæ¨™ç±¤åˆ†ä½ˆï¼š{pd.Series(sentiments).value_counts().to_dict()}")
            else:
                raise ValueError("å…ƒæ•¸æ“šä¸­ç¼ºå°‘ 'sentiment_numeric'ã€'sentiment' å’Œ 'review_stars' æ¬„ä½")
        else:
            # æå–æƒ…æ„Ÿæ¨™ç±¤ä¸¦è½‰æ›ç‚ºæ•¸å€¼
            sentiments = metadata['sentiment'].values
            # ç·¨ç¢¼æ¨™ç±¤
            encoded_labels = self.label_encoder.fit_transform(sentiments)
        
        # è™•ç†ç‰¹å¾µï¼šå„ªå…ˆä½¿ç”¨èåˆç‰¹å¾µï¼Œå¦å‰‡ä½¿ç”¨åŸå§‹ç‰¹å¾µ
        if fused_features is not None:
            logger.info("ä½¿ç”¨èåˆç‰¹å¾µé€²è¡Œåˆ†é¡")
            features = fused_features.copy()
            
            # ç¢ºä¿èåˆç‰¹å¾µæ•¸é‡èˆ‡å…ƒæ•¸æ“šåŒ¹é…
            if len(features) != len(metadata):
                raise ValueError(f"èåˆç‰¹å¾µæ•¸é‡ ({len(features)}) èˆ‡å…ƒæ•¸æ“šæ•¸é‡ ({len(metadata)}) ä¸åŒ¹é…")
            
            logger.info(f"èåˆç‰¹å¾µå½¢ç‹€: {features.shape}")
        else:
            # ä½¿ç”¨åŸå§‹åµŒå…¥å‘é‡
            if original_embeddings is None:
                # å˜—è©¦è¼‰å…¥ç·¨ç¢¼å™¨åµŒå…¥å‘é‡
                if self.output_dir:
                    # ä½¿ç”¨é€šç”¨çš„æª”æ¡ˆæª¢æ¸¬é‚è¼¯
                    try:
                        from .attention_processor import AttentionProcessor
                        temp_processor = AttentionProcessor(output_dir=self.output_dir, encoder_type=self.encoder_type)
                        embeddings_file = temp_processor._find_existing_embeddings(self.encoder_type)
                        
                        if embeddings_file and os.path.exists(embeddings_file):
                            original_embeddings = np.load(embeddings_file)
                            logger.info(f"å·²è¼‰å…¥ {self.encoder_type.upper()} åµŒå…¥å‘é‡ï¼Œå½¢ç‹€: {original_embeddings.shape}")
                            logger.info(f"æª”æ¡ˆä¾†æº: {embeddings_file}")
                        else:
                            raise ValueError(f"ç„¡æ³•æ‰¾åˆ° {self.encoder_type.upper()} åµŒå…¥å‘é‡æ–‡ä»¶ã€‚è«‹æä¾› original_embeddings åƒæ•¸æˆ–ç¢ºä¿ {self.encoder_type.upper()} ç‰¹å¾µå‘é‡æ–‡ä»¶å­˜åœ¨ã€‚")
                    except Exception as e:
                        raise ValueError(f"è¼‰å…¥ {self.encoder_type.upper()} åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ã€‚è«‹æä¾› original_embeddings åƒæ•¸ã€‚")
                else:
                    raise ValueError(f"ç„¡æ³•æ‰¾åˆ° {self.encoder_type.upper()} åµŒå…¥å‘é‡ã€‚è«‹æä¾› original_embeddings åƒæ•¸ã€‚")
            
            # ç¢ºä¿åµŒå…¥å‘é‡æ•¸é‡èˆ‡å…ƒæ•¸æ“šåŒ¹é…
            if len(original_embeddings) != len(metadata):
                raise ValueError(f"åµŒå…¥å‘é‡æ•¸é‡ ({len(original_embeddings)}) èˆ‡å…ƒæ•¸æ“šæ•¸é‡ ({len(metadata)}) ä¸åŒ¹é…")
            # ä¿®æ­£ï¼šä½¿ç”¨åŸå§‹BERTåµŒå…¥å‘é‡ä½œç‚ºä¸»è¦ç‰¹å¾µ
            features = original_embeddings.copy()
            
            # ä¿®æ­£ï¼šè¨ˆç®—èˆ‡é¢å‘å‘é‡çš„ç›¸ä¼¼åº¦ä½œç‚ºé¡å¤–ç‰¹å¾µ
            aspect_names = sorted(aspect_vectors.keys())
            similarity_features = []
            
            logger.info(f"è¨ˆç®—æ¯å€‹æ–‡æª”èˆ‡ {len(aspect_names)} å€‹é¢å‘å‘é‡çš„ç›¸ä¼¼åº¦...")
            
            # æª¢æŸ¥ç¶­åº¦ç›¸å®¹æ€§
            first_embedding = original_embeddings[0]
            first_aspect_vector = aspect_vectors[aspect_names[0]]
            
            if first_embedding.shape[0] != first_aspect_vector.shape[0]:
                error_msg = f"ç¶­åº¦ä¸åŒ¹é…: æ–‡æª”åµŒå…¥å‘é‡ç¶­åº¦ {first_embedding.shape[0]}, é¢å‘å‘é‡ç¶­åº¦ {first_aspect_vector.shape[0]}"
                logger.error(error_msg)
                logger.error(f"é€™é€šå¸¸æ˜¯ç”±æ–¼æ³¨æ„åŠ›åˆ†æå’Œåˆ†é¡è©•ä¼°ä½¿ç”¨äº†ä¸åŒçš„ç·¨ç¢¼å™¨é€ æˆçš„")
                logger.error(f"ç•¶å‰ç·¨ç¢¼å™¨é¡å‹: {self.encoder_type.upper()}")
                
                # å˜—è©¦ä¿®å¾©ï¼šå¦‚æœé¢å‘å‘é‡ç¶­åº¦æ˜¯1024è€Œæ–‡æª”å‘é‡æ˜¯768ï¼Œèªªæ˜é¢å‘å‘é‡ä¾†è‡ªä¸åŒç·¨ç¢¼å™¨
                if first_aspect_vector.shape[0] == 1024 and first_embedding.shape[0] == 768:
                    logger.warning("æª¢æ¸¬åˆ°é¢å‘å‘é‡ä¾†è‡ª1024ç¶­ç·¨ç¢¼å™¨ï¼ˆå¯èƒ½æ˜¯GPT/T5ï¼‰ï¼Œä½†æ–‡æª”å‘é‡æ˜¯768ç¶­ï¼ˆBERTï¼‰")
                    logger.warning("å»ºè­°é‡æ–°é‹è¡Œå®Œæ•´çš„æµæ°´ç·šä»¥ç¢ºä¿ç·¨ç¢¼å™¨ä¸€è‡´æ€§")
                elif first_aspect_vector.shape[0] == 768 and first_embedding.shape[0] == 1024:
                    logger.warning("æª¢æ¸¬åˆ°é¢å‘å‘é‡ä¾†è‡ª768ç¶­ç·¨ç¢¼å™¨ï¼ˆBERTï¼‰ï¼Œä½†æ–‡æª”å‘é‡æ˜¯1024ç¶­ï¼ˆå¯èƒ½æ˜¯GPT/T5ï¼‰")
                    logger.warning("å»ºè­°é‡æ–°é‹è¡Œå®Œæ•´çš„æµæ°´ç·šä»¥ç¢ºä¿ç·¨ç¢¼å™¨ä¸€è‡´æ€§")
                
                raise ValueError(f"{error_msg}ã€‚è«‹ç¢ºä¿æ³¨æ„åŠ›åˆ†æå’Œåˆ†é¡è©•ä¼°ä½¿ç”¨ç›¸åŒçš„ç·¨ç¢¼å™¨é¡å‹ã€‚")
            
            for i, embedding in enumerate(original_embeddings):
                doc_similarities = []
                for aspect_name in aspect_names:
                    aspect_vector = aspect_vectors[aspect_name]
                    # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
                    similarity = np.dot(embedding, aspect_vector) / (
                        np.linalg.norm(embedding) * np.linalg.norm(aspect_vector) + 1e-8
                    )
                    doc_similarities.append(similarity)
                similarity_features.append(doc_similarities)
            
            similarity_features = np.array(similarity_features)
            
            # çµ„åˆåŸå§‹ç‰¹å¾µå’Œç›¸ä¼¼åº¦ç‰¹å¾µ
            features = np.concatenate([original_embeddings, similarity_features], axis=1)
        
        prepare_time = time.time() - start_time
        
        # åªé¡¯ç¤ºé—œéµä¿¡æ¯
        feature_type = "èåˆç‰¹å¾µ" if fused_features is not None else f"{self.encoder_type.upper()}+ç›¸ä¼¼åº¦ç‰¹å¾µ"
        logger.debug(f"ç‰¹å¾µæº–å‚™å®Œæˆ - {features.shape[0]}æ¨£æœ¬ x {features.shape[1]}ç¶­ ({feature_type}, {prepare_time:.1f}s)")
        
        self.feature_vectors = features
        self.labels = encoded_labels
        
        return features, encoded_labels
    
    def train(self, features: np.ndarray, labels: np.ndarray, 
              model_type: str = None, test_size: float = 0.2,
              original_data: pd.DataFrame = None) -> Dict[str, Any]:
        """
        è¨“ç·´åˆ†é¡æ¨¡å‹
        
        Args:
            features: ç‰¹å¾µçŸ©é™£
            labels: æ¨™ç±¤æ•¸çµ„
            model_type: æ¨¡å‹é¡å‹
            test_size: æ¸¬è©¦é›†æ¯”ä¾‹
            original_data: åŸå§‹æ•¸æ“šDataFrameï¼Œç”¨æ–¼ä¿å­˜æ¸¬è©¦é›†æ–‡æœ¬
            
        Returns:
            è©•ä¼°çµæœå­—å…¸
        """
        # å¦‚æœæ²’æœ‰æŒ‡å®šæ¨¡å‹é¡å‹ï¼Œä½¿ç”¨é è¨­å€¼
        if model_type is None:
            model_type = self.model_type
            
        if model_type not in self.available_models:
            available_models = list(self.available_models.keys())
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {model_type}ã€‚å¯ç”¨çš„æ¨¡å‹: {available_models}")
        
        start_time = time.time()
        logger.debug(f"é–‹å§‹è¨“ç·´ {model_type} æ¨¡å‹ ({self.device_info['description']})")
        
        # åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦é›†
        split_start = time.time()
        if original_data is not None:
            # å¦‚æœæœ‰åŸå§‹æ•¸æ“šï¼ŒåŒæ™‚åˆ†å‰²åŸå§‹æ•¸æ“šä»¥ä¿æŒå°æ‡‰é—œä¿‚
            X_train, X_test, y_train, y_test, data_train, data_test = train_test_split(
                features, labels, original_data, test_size=test_size, random_state=42, stratify=labels
            )
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                features, labels, test_size=test_size, random_state=42, stratify=labels
            )
            data_test = None
        
        split_time = time.time() - split_start
        logger.debug(f"æ•¸æ“šåˆ†å‰²å®Œæˆ - è¨“ç·´:{X_train.shape[0]} æ¸¬è©¦:{X_test.shape[0]} ({split_time:.1f}s)")
        
        # é¸æ“‡æ¨¡å‹
        self.model = self.available_models[model_type]
        self.model_type = model_type
        
        # è¨“ç·´æ¨¡å‹
        train_start = time.time()
        
        # é‡å°XGBoostçš„GPUé…ç½®ï¼ˆç°¡åŒ–è¼¸å‡ºï¼‰
        if model_type == 'xgboost' and self.device_info['has_gpu']:
            try:
                # ç¢ºä¿XGBoostä½¿ç”¨GPUé…ç½®
                import xgboost as xgb
                xgb_version = xgb.__version__
                xgb_major_version = int(xgb_version.split('.')[0])
                
                if xgb_major_version >= 2:
                    current_device = getattr(self.model, 'device', None)
                    if current_device != 'cuda':
                        self.model.set_params(device='cuda')
                else:
                    current_tree_method = getattr(self.model, 'tree_method', None)
                    if current_tree_method != 'gpu_hist':
                        self.model.set_params(tree_method='gpu_hist', gpu_id=0)
                
                logger.debug(f"XGBoostä½¿ç”¨GPUåŠ é€Ÿ")
            except Exception as e:
                logger.debug(f"XGBoost GPUé…ç½®è­¦å‘Š: {e}")
        
        self.model.fit(X_train, y_train)
        train_time = time.time() - train_start
        
        # é æ¸¬
        predict_start = time.time()
        train_pred = self.model.predict(X_train)
        test_pred = self.model.predict(X_test)
        test_pred_proba = self.model.predict_proba(X_test)
        predict_time = time.time() - predict_start
        
        logger.debug(f"æ¨¡å‹è¨“ç·´+é æ¸¬å®Œæˆ ({train_time:.1f}s + {predict_time:.1f}s)")
        
        # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
        results = self._calculate_metrics(
            y_train, train_pred, y_test, test_pred, test_pred_proba
        )
        
        # æ·»åŠ æ™‚é–“ä¿¡æ¯
        total_time = time.time() - start_time
        timing_info = {
            'total_time': total_time,
            'split_time': split_time,
            'train_time': train_time,
            'predict_time': predict_time,
            'model_type': model_type,
            'device_info': self.device_info
        }
        
        results['timing_info'] = timing_info
        # ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œä¹Ÿç›´æ¥è¨­å®š training_time éµ
        results['training_time'] = train_time
        
        # ä¿å­˜é æ¸¬çµæœè©³ç´°ä¿¡æ¯
        # å°‡ç·¨ç¢¼çš„æ¨™ç±¤è½‰æ›å›åŸå§‹æ¨™ç±¤åç¨±
        # ä¿®æ­£ï¼šæª¢æŸ¥LabelEncoderæ˜¯å¦å·²ç¶“fitted
        if hasattr(self.label_encoder, 'classes_') and self.label_encoder.classes_ is not None:
            true_label_names = self.label_encoder.inverse_transform(y_test)
            predicted_label_names = self.label_encoder.inverse_transform(test_pred)
            class_names_list = self.label_encoder.classes_.tolist()
        else:
            # å¦‚æœæ²’æœ‰fittedï¼Œä½¿ç”¨æ•¸å­—æ¨™ç±¤
            true_label_names = [f"label_{label}" for label in y_test]
            predicted_label_names = [f"label_{label}" for label in test_pred]
            unique_labels = np.unique(np.concatenate([y_train, y_test]))
            class_names_list = [f"label_{label}" for label in unique_labels]
        
        # ä¿å­˜æ¸¬è©¦é›†çš„æ–‡æœ¬ä¿¡æ¯ä»¥ä¾¿å¾ŒçºŒåŒ¹é…
        test_texts = []
        if data_test is not None:
            # ç²å–æ¸¬è©¦é›†çš„æ–‡æœ¬
            text_column = None
            for col in ['processed_text', 'text', 'review', 'content']:
                if col in data_test.columns:
                    text_column = col
                    break
            
            if text_column:
                test_texts = data_test[text_column].tolist()
        
        results['prediction_details'] = {
            'test_indices': None,  # ç”±æ–¼è¨“ç·´æ™‚æ²’æœ‰åŸå§‹ç´¢å¼•ï¼Œé€™è£¡è¨­ç‚ºNone
            'true_labels': y_test.tolist(),  # ç·¨ç¢¼å¾Œçš„æ¨™ç±¤
            'predicted_labels': test_pred.tolist(),  # ç·¨ç¢¼å¾Œçš„é æ¸¬æ¨™ç±¤
            'true_label_names': true_label_names.tolist() if hasattr(true_label_names, 'tolist') else list(true_label_names),  # åŸå§‹æ¨™ç±¤åç¨±
            'predicted_label_names': predicted_label_names.tolist() if hasattr(predicted_label_names, 'tolist') else list(predicted_label_names),  # é æ¸¬æ¨™ç±¤åç¨±
            'predicted_probabilities': test_pred_proba.tolist(),
            'class_names': class_names_list,
            'test_texts': test_texts  # æ¸¬è©¦é›†æ–‡æœ¬ï¼Œç”¨æ–¼å¾ŒçºŒåŒ¹é…
        }
        
        # ä¿å­˜æ¨¡å‹
        if self.output_dir:
            self._save_model()
        
        # ç°¡åŒ–çš„çµ±è¨ˆè¼¸å‡º
        logger.debug(f"è¨“ç·´çµ±è¨ˆ - ç¸½è€—æ™‚:{total_time:.1f}s æº–ç¢ºç‡:{results['test_accuracy']:.4f} (åˆ†å‰²:{split_time:.1f}s è¨“ç·´:{train_time:.1f}s é æ¸¬:{predict_time:.1f}s)")
        
        return results
    
    def predict(self, features: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        é æ¸¬æƒ…æ„Ÿæ¨™ç±¤
        
        Args:
            features: ç‰¹å¾µçŸ©é™£
            
        Returns:
            predictions: é æ¸¬æ¨™ç±¤
            probabilities: é æ¸¬æ©Ÿç‡
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨ train() æ–¹æ³•")
        
        predictions = self.model.predict(features)
        probabilities = self.model.predict_proba(features)
        
        return predictions, probabilities
    
    def predict_with_details(self, features: np.ndarray, original_data: Optional[pd.DataFrame] = None) -> Dict[str, Any]:
        """
        é æ¸¬æƒ…æ„Ÿæ¨™ç±¤ä¸¦è¿”å›è©³ç´°çµæœ
        
        Args:
            features: ç‰¹å¾µçŸ©é™£
            original_data: åŸå§‹æ•¸æ“šï¼ˆåŒ…å«æ–‡æœ¬å’ŒçœŸå¯¦æ¨™ç±¤ï¼‰
            
        Returns:
            åŒ…å«é æ¸¬çµæœå’Œè©³ç´°ä¿¡æ¯çš„å­—å…¸
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨ train() æ–¹æ³•")
        
        predictions = self.model.predict(features)
        probabilities = self.model.predict_proba(features)
        
        # è§£ç¢¼é æ¸¬æ¨™ç±¤
        predicted_labels = self.label_encoder.inverse_transform(predictions)
        
        result = {
            'predictions': predictions,
            'predicted_labels': predicted_labels.tolist(),
            'probabilities': probabilities.tolist(),
            'class_names': self.label_encoder.classes_.tolist()
        }
        
        # å¦‚æœæœ‰åŸå§‹æ•¸æ“šï¼Œæ·»åŠ è©³ç´°æ¯”å°ä¿¡æ¯
        if original_data is not None:
            result['detailed_comparison'] = self._create_detailed_comparison(
                original_data, predicted_labels, probabilities
            )
        
        return result
    
    def evaluate_attention_mechanisms(self, attention_results: Dict[str, Any], 
                                    metadata: pd.DataFrame,
                                    original_embeddings: np.ndarray = None,
                                    model_type: str = None) -> Dict[str, Dict]:
        """
        è©•ä¼°ä¸åŒæ³¨æ„åŠ›æ©Ÿåˆ¶çš„åˆ†é¡æ€§èƒ½
        
        Args:
            attention_results: æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æçµæœ
            metadata: åŒ…å«çœŸå¯¦æ¨™ç±¤çš„å…ƒæ•¸æ“š
            original_embeddings: åŸå§‹BERTåµŒå…¥å‘é‡ï¼ˆä¿®æ­£ï¼šæ–°å¢æ­¤åƒæ•¸ï¼‰
            model_type: æŒ‡å®šåˆ†é¡å™¨é¡å‹ï¼Œå¦‚æœNoneå‰‡ä½¿ç”¨é è¨­å€¼
            
        Returns:
            å„æ³¨æ„åŠ›æ©Ÿåˆ¶çš„åˆ†é¡æ€§èƒ½çµæœ
        """
        evaluation_results = {}
        
        # ä¿®æ­£ï¼šå¦‚æœæ²’æœ‰æä¾›original_embeddingsï¼Œå˜—è©¦è¼‰å…¥ï¼ˆæ”¯æ´å¤šç¨®ç·¨ç¢¼å™¨ï¼‰
        if original_embeddings is None:
            if self.output_dir:
                # ä½¿ç”¨é€šç”¨çš„æª”æ¡ˆæª¢æ¸¬é‚è¼¯
                try:
                    from .attention_processor import AttentionProcessor
                    temp_processor = AttentionProcessor(output_dir=self.output_dir, encoder_type=self.encoder_type)
                    embeddings_file = temp_processor._find_existing_embeddings(self.encoder_type)
                    
                    if embeddings_file and os.path.exists(embeddings_file):
                        original_embeddings = np.load(embeddings_file)
                        logger.info(f"å·²è¼‰å…¥ {self.encoder_type.upper()} åµŒå…¥å‘é‡ç”¨æ–¼åˆ†é¡è©•ä¼°ï¼Œå½¢ç‹€: {original_embeddings.shape}")
                        logger.info(f"æª”æ¡ˆä¾†æº: {embeddings_file}")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ° {self.encoder_type.upper()} åµŒå…¥å‘é‡æ–‡ä»¶ï¼Œå°‡å˜—è©¦å¾prepare_featuresæ–¹æ³•ä¸­è¼‰å…¥")
                except Exception as e:
                    logger.warning(f"è¼‰å…¥ {self.encoder_type.upper()} åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œå°‡å˜—è©¦å¾prepare_featuresæ–¹æ³•ä¸­è¼‰å…¥")
        
        # éæ¿¾å‡ºæœ‰æ•ˆçš„æ³¨æ„åŠ›æ©Ÿåˆ¶
        valid_mechanisms = []
        print(f"ğŸ” æª¢æŸ¥æ³¨æ„åŠ›çµæœï¼Œç¸½å…± {len(attention_results)} å€‹é …ç›®:")
        for mechanism_name, mechanism_result in attention_results.items():
            print(f"   - {mechanism_name}: {type(mechanism_result)}")
            if isinstance(mechanism_result, dict):
                print(f"     éµ: {list(mechanism_result.keys())}")
            
            if mechanism_name != 'comparison' and isinstance(mechanism_result, dict) and 'aspect_vectors' in mechanism_result:
                valid_mechanisms.append((mechanism_name, mechanism_result))
                print(f"   âœ… {mechanism_name} æœ‰æ•ˆï¼ŒåŒ…å«aspect_vectors")
            else:
                print(f"   âŒ {mechanism_name} ç„¡æ•ˆæˆ–ç¼ºå°‘aspect_vectors")
        
        print(f"ğŸ“Š é–‹å§‹è©•ä¼° {len(valid_mechanisms)} ç¨®æ³¨æ„åŠ›æ©Ÿåˆ¶çš„åˆ†é¡æ€§èƒ½...")
        
        # å¦‚æœæ²’æœ‰æœ‰æ•ˆæ©Ÿåˆ¶ï¼Œæå‰è¿”å›
        if len(valid_mechanisms) == 0:
            print(f"âš ï¸  è­¦å‘Šï¼šæ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ³¨æ„åŠ›æ©Ÿåˆ¶é€²è¡Œåˆ†é¡è©•ä¼°")
            return {'comparison': {'error': 'æ²’æœ‰æœ‰æ•ˆçš„æ³¨æ„åŠ›æ©Ÿåˆ¶çµæœ'}}
        
        for mechanism_name, mechanism_result in tqdm(valid_mechanisms, desc="è©•ä¼°æ³¨æ„åŠ›æ©Ÿåˆ¶"):
            print(f"   ğŸ” æ­£åœ¨è©•ä¼° {mechanism_name} æ³¨æ„åŠ›æ©Ÿåˆ¶...")
            logger.info(f"è©•ä¼° {mechanism_name} æ³¨æ„åŠ›æ©Ÿåˆ¶çš„åˆ†é¡æ€§èƒ½...")
            
            try:
                # æº–å‚™ç‰¹å¾µï¼ˆä¿®æ­£ï¼šå‚³éåŸå§‹åµŒå…¥å‘é‡ï¼‰
                print(f"      ğŸ“‹ æº–å‚™ç‰¹å¾µå‘é‡...")
                aspect_vectors = mechanism_result['aspect_vectors']
                features, labels = self.prepare_features(aspect_vectors, metadata, original_embeddings)
                
                # è¨“ç·´å’Œè©•ä¼°
                print(f"      ğŸ¤– è¨“ç·´åˆ†é¡å™¨...")
                # ä½¿ç”¨æŒ‡å®šçš„model_typeæˆ–é è¨­å€¼
                train_model_type = model_type if model_type is not None else self.model_type
                results = self.train(features, labels, model_type=train_model_type, original_data=metadata)
                
                # æ·»åŠ æ³¨æ„åŠ›æ©Ÿåˆ¶ç‰¹å®šä¿¡æ¯
                results['attention_mechanism'] = mechanism_name
                results['mechanism_metrics'] = mechanism_result.get('metrics', {})
                
                evaluation_results[mechanism_name] = results
                
                print(f"      âœ… {mechanism_name} è©•ä¼°å®Œæˆ - æº–ç¢ºç‡: {results['test_accuracy']:.4f}, "
                      f"F1åˆ†æ•¸: {results['test_f1']:.4f}")
                
            except Exception as e:
                print(f"      âŒ è©•ä¼° {mechanism_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                logger.error(f"è©•ä¼° {mechanism_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                
                # å³ä½¿å¤±æ•—ä¹Ÿè¨˜éŒ„éŒ¯èª¤ä¿¡æ¯
                evaluation_results[mechanism_name] = {
                    'error': str(e),
                    'attention_mechanism': mechanism_name,
                    'test_accuracy': 0.0,
                    'test_f1': 0.0,
                    'training_time': 0.0
                }
                continue
        
        # æ¯”è¼ƒä¸åŒæ³¨æ„åŠ›æ©Ÿåˆ¶çš„æ€§èƒ½
        print(f"   ğŸ“ˆ æ¯”è¼ƒä¸åŒæ³¨æ„åŠ›æ©Ÿåˆ¶çš„æ€§èƒ½...")
        comparison = self._compare_mechanisms(evaluation_results)
        evaluation_results['comparison'] = comparison
        
        print(f"âœ… åˆ†é¡æ€§èƒ½è©•ä¼°å®Œæˆï¼")
        if comparison and 'best_mechanism' in comparison:
            print(f"ğŸ† æœ€ä½³åˆ†é¡æ€§èƒ½æ©Ÿåˆ¶: {comparison['best_mechanism']}")
            # å®‰å…¨è¨ªå• summary éµ
            summary = comparison.get('summary', {})
            if summary:
                print(f"ğŸ“Š æœ€ä½³æº–ç¢ºç‡: {summary.get('best_accuracy', 0):.4f}")
                print(f"ğŸ“Š æœ€ä½³F1åˆ†æ•¸: {summary.get('best_f1', 0):.4f}")
            else:
                print("ğŸ“Š è­¦å‘Šï¼šç„¡æ³•ç²å–æ€§èƒ½çµ±è¨ˆæ‘˜è¦")
        else:
            print("âš ï¸  è­¦å‘Šï¼šç„¡æ³•é€²è¡Œæ€§èƒ½æ¯”è¼ƒ")
        
        return evaluation_results
    
    def _calculate_metrics(self, y_train: np.ndarray, train_pred: np.ndarray,
                          y_test: np.ndarray, test_pred: np.ndarray, 
                          test_pred_proba: np.ndarray) -> Dict[str, Any]:
        """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
        # æº–ç¢ºç‡
        train_accuracy = accuracy_score(y_train, train_pred)
        test_accuracy = accuracy_score(y_test, test_pred)
        
        # ç²¾ç¢ºç‡ã€å¬å›ç‡ã€F1åˆ†æ•¸
        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
            y_train, train_pred, average='weighted'
        )
        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
            y_test, test_pred, average='weighted'
        )
        
        # é¡å¤–è¨ˆç®—ï¼šä¹Ÿè¨ˆç®—macroå¹³å‡ï¼Œç”¨æ–¼æ¯”è¼ƒ
        test_precision_macro, test_recall_macro, test_f1_macro, _ = precision_recall_fscore_support(
            y_test, test_pred, average='macro'
        )
        
        print(f"ğŸ” åŠ æ¬Šå¹³å‡ vs å®å¹³å‡æ¯”è¼ƒï¼š")
        print(f"   ç²¾ç¢ºç‡ - åŠ æ¬Š: {test_precision:.6f}, å®: {test_precision_macro:.6f}")
        print(f"   å¬å›ç‡ - åŠ æ¬Š: {test_recall:.6f}, å®: {test_recall_macro:.6f}")
        print(f"   F1åˆ†æ•¸ - åŠ æ¬Š: {test_f1:.6f}, å®: {test_f1_macro:.6f}")
        
        # è§£é‡‹ç‚ºä»€éº¼æŒ‡æ¨™å¯èƒ½ç›¸åŒ
        if abs(test_accuracy - test_precision) < 0.001 and abs(test_accuracy - test_recall) < 0.001:
            print(f"âš ï¸  æ³¨æ„ï¼šæº–ç¢ºç‡ã€ç²¾ç¢ºç‡ã€å¬å›ç‡éå¸¸æ¥è¿‘ï¼Œå¯èƒ½åŸå› ï¼š")
            print(f"   1. æ•¸æ“šé›†é«˜åº¦å¹³è¡¡")
            print(f"   2. æ¨¡å‹æ€§èƒ½æ¥µä½³")
            print(f"   3. ä½¿ç”¨åŠ æ¬Šå¹³å‡å°è‡´æŒ‡æ¨™è¶¨åŒ")
            print(f"   å»ºè­°æŸ¥çœ‹å®å¹³å‡å’Œå„é¡åˆ¥æŒ‡æ¨™ä»¥ç²å¾—æ›´è©³ç´°åˆ†æ")
        
        # æ··æ·†çŸ©é™£
        confusion_mat = confusion_matrix(y_test, test_pred)
        
        # åˆ†é¡å ±å‘Š
        # ä¿®æ­£ï¼šæª¢æŸ¥LabelEncoderæ˜¯å¦å·²ç¶“fittedï¼Œé¿å…AttributeError
        if hasattr(self.label_encoder, 'classes_') and self.label_encoder.classes_ is not None:
            class_names = self.label_encoder.classes_
        else:
            # å¦‚æœæ²’æœ‰é¡åˆ¥åç¨±ï¼Œä½¿ç”¨å”¯ä¸€å€¼
            unique_labels = np.unique(np.concatenate([y_train, y_test]))
            class_names = [f"class_{label}" for label in unique_labels]
        
        classification_rep = classification_report(
            y_test, test_pred, target_names=class_names, output_dict=True
        )
        
        # èª¿è©¦è¼¸å‡ºï¼šè©³ç´°åˆ†æç‚ºä»€éº¼æŒ‡æ¨™ç›¸åŒ
        print(f"ğŸ” æŒ‡æ¨™èª¿è©¦ï¼š")
        print(f"   æ¸¬è©¦æº–ç¢ºç‡: {test_accuracy:.6f}")
        print(f"   æ¸¬è©¦ç²¾ç¢ºç‡: {test_precision:.6f}")
        print(f"   æ¸¬è©¦å¬å›ç‡: {test_recall:.6f}")
        print(f"   æ¸¬è©¦F1åˆ†æ•¸: {test_f1:.6f}")
        
        # æª¢æŸ¥é¡åˆ¥åˆ†ä½ˆ
        unique_labels, counts = np.unique(y_test, return_counts=True)
        print(f"ğŸ” æ¸¬è©¦é›†é¡åˆ¥åˆ†ä½ˆ: {dict(zip(unique_labels, counts))}")
        
        # æª¢æŸ¥æ··æ·†çŸ©é™£å°è§’ç·š
        print(f"ğŸ” æ··æ·†çŸ©é™£:")
        print(confusion_mat)
        
        # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ç²¾ç¢ºç‡å’Œå¬å›ç‡
        per_class_precision, per_class_recall, per_class_f1, support = precision_recall_fscore_support(
            y_test, test_pred, average=None
        )
        print(f"ğŸ” å„é¡åˆ¥ç²¾ç¢ºç‡: {per_class_precision}")
        print(f"ğŸ” å„é¡åˆ¥å¬å›ç‡: {per_class_recall}")
        print(f"ğŸ” å„é¡åˆ¥F1åˆ†æ•¸: {per_class_f1}")
        print(f"ğŸ” å„é¡åˆ¥æ”¯æŒæ•¸: {support}")
        
        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰é æ¸¬éƒ½ç›¸åŒ
        unique_preds = np.unique(test_pred)
        print(f"ğŸ” é æ¸¬å€¼ç¨®é¡: {unique_preds}")
        print(f"ğŸ” é æ¸¬æº–ç¢ºç‡åˆ†ä½ˆ: {np.bincount(test_pred) / len(test_pred)}")
        
        return {
            'train_accuracy': float(train_accuracy),
            'test_accuracy': float(test_accuracy),
            'train_precision': float(train_precision),
            'test_precision': float(test_precision),
            'train_recall': float(train_recall),
            'test_recall': float(test_recall),
            'train_f1': float(train_f1),
            'test_f1': float(test_f1),
            # é¡å¤–æä¾›å®å¹³å‡æŒ‡æ¨™ä»¥ä¾›æ¯”è¼ƒ
            'test_precision_macro': float(test_precision_macro),
            'test_recall_macro': float(test_recall_macro),
            'test_f1_macro': float(test_f1_macro),
            'confusion_matrix': confusion_mat.tolist(),
            'classification_report': classification_rep,
            'class_names': class_names.tolist() if hasattr(class_names, 'tolist') else list(class_names),
            'model_type': self.model_type,
            # æ¯å€‹é¡åˆ¥çš„è©³ç´°æŒ‡æ¨™
            'per_class_precision': per_class_precision.tolist(),
            'per_class_recall': per_class_recall.tolist(),
            'per_class_f1': per_class_f1.tolist(),
            'per_class_support': support.tolist()
        }
    
    def _compare_mechanisms(self, evaluation_results: Dict[str, Dict]) -> Dict[str, Any]:
        """æ¯”è¼ƒä¸åŒæ³¨æ„åŠ›æ©Ÿåˆ¶çš„æ€§èƒ½"""
        # å¦‚æœæ²’æœ‰è©•ä¼°çµæœï¼Œè¿”å›ç©ºçš„ä½†çµæ§‹å®Œæ•´çš„æ¯”è¼ƒçµæœ
        if not evaluation_results:
            return {
                'best_mechanism': None,
                'accuracy_ranking': [],
                'f1_ranking': [],
                'summary': {
                    'best_accuracy': 0,
                    'best_f1': 0,
                    'mechanisms_tested': 0,
                    'error': 'No evaluation results available'
                }
            }
        
        # æå–æ€§èƒ½æŒ‡æ¨™
        mechanisms = []
        accuracies = []
        f1_scores = []
        precisions = []
        recalls = []
        
        for mechanism, results in evaluation_results.items():
            if mechanism == 'comparison':
                continue
            
            # è·³ééŒ¯èª¤çš„çµæœï¼Œä½†è¨˜éŒ„å®ƒå€‘
            if 'error' in results:
                print(f"   âš ï¸  è·³éå¤±æ•—çš„æ©Ÿåˆ¶: {mechanism} (éŒ¯èª¤: {results['error']})")
                continue
            
            # æ·»åŠ å®‰å…¨æª¢æŸ¥ï¼Œç¢ºä¿çµæœåŒ…å«å¿…è¦çš„éµ
            try:
                mechanisms.append(mechanism)
                accuracies.append(results.get('test_accuracy', 0))
                f1_scores.append(results.get('test_f1', 0))
                precisions.append(results.get('test_precision', 0))
                recalls.append(results.get('test_recall', 0))
            except (KeyError, TypeError) as e:
                logger.warning(f"æ©Ÿåˆ¶ {mechanism} çš„çµæœä¸å®Œæ•´ï¼Œè·³é: {str(e)}")
                continue
        
        # ç¢ºä¿æœ‰æœ‰æ•ˆçš„çµæœæ‰é€²è¡Œæ’åº
        if not mechanisms:
            return {
                'best_mechanism': None,
                'accuracy_ranking': [],
                'f1_ranking': [],
                'summary': {
                    'best_accuracy': 0,
                    'best_f1': 0,
                    'mechanisms_tested': 0,
                    'error': 'No valid mechanism results found'
                }
            }
        
        # æ’åº
        accuracy_ranking = sorted(zip(mechanisms, accuracies), key=lambda x: x[1], reverse=True)
        f1_ranking = sorted(zip(mechanisms, f1_scores), key=lambda x: x[1], reverse=True)
        
        # æ‰¾å‡ºæœ€ä½³æ©Ÿåˆ¶
        best_mechanism = accuracy_ranking[0][0] if accuracy_ranking else None
        
        return {
            'best_mechanism': best_mechanism,
            'accuracy_ranking': accuracy_ranking,
            'f1_ranking': f1_ranking,
            'summary': {
                'best_accuracy': accuracy_ranking[0][1] if accuracy_ranking else 0,
                'best_f1': f1_ranking[0][1] if f1_ranking else 0,
                'mechanisms_tested': len(mechanisms)
            }
        }
    
    def _save_model(self):
        """ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹åˆ°runç›®éŒ„æ ¹ç›®éŒ„"""
        if self.model is None or self.output_dir is None:
            return

        # ç¢ºä¿ä¿å­˜åˆ°runç›®éŒ„çš„æ ¹ç›®éŒ„
        if any(subdir in self.output_dir for subdir in ["01_preprocessing", "02_bert_encoding", "03_attention_testing", "04_analysis"]):
            # å¦‚æœè¼¸å‡ºç›®éŒ„æ˜¯å­ç›®éŒ„ï¼Œæ”¹ç‚ºçˆ¶ç›®éŒ„ï¼ˆrunç›®éŒ„æ ¹ç›®éŒ„ï¼‰
            run_dir = os.path.dirname(self.output_dir)
        else:
            run_dir = self.output_dir

        model_path = os.path.join(run_dir, f"sentiment_classifier_{self.model_type}.pkl")
        encoder_path = os.path.join(run_dir, "label_encoder.pkl")

        joblib.dump(self.model, model_path)
        joblib.dump(self.label_encoder, encoder_path)

        logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
        logger.info(f"æ¨™ç±¤ç·¨ç¢¼å™¨å·²ä¿å­˜è‡³: {encoder_path}")
    
    def load_model(self, model_path: str, encoder_path: str):
        """è¼‰å…¥é è¨“ç·´æ¨¡å‹"""
        self.model = joblib.load(model_path)
        self.label_encoder = joblib.load(encoder_path)
        
        logger.info(f"æ¨¡å‹å·²è¼‰å…¥: {model_path}")
        logger.info(f"æ¨™ç±¤ç·¨ç¢¼å™¨å·²è¼‰å…¥: {encoder_path}")
    
    def _create_detailed_comparison(self, original_data: pd.DataFrame, 
                                  predicted_labels: np.ndarray, 
                                  probabilities: np.ndarray) -> List[Dict]:
        """å‰µå»ºè©³ç´°çš„æ¯”å°çµæœ"""
        detailed_results = []
        
        for i in range(len(original_data)):
            row = original_data.iloc[i]
            
            # ç²å–åŸå§‹æ–‡æœ¬å’Œæ¨™ç±¤
            original_text = str(row.get('processed_text', row.get('text', row.get('review', ''))))
            original_label = str(row.get('sentiment', 'unknown'))
            
            # æˆªæ–·éé•·çš„æ–‡æœ¬
            if len(original_text) > 100:
                display_text = original_text[:97] + "..."
            else:
                display_text = original_text
            
            predicted_label = predicted_labels[i]
            is_correct = predicted_label == original_label
            confidence = float(np.max(probabilities[i]))
            
            detailed_results.append({
                'index': i,
                'original_text': display_text,
                'original_label': original_label,
                'predicted_label': predicted_label,
                'is_correct': is_correct,
                'confidence': confidence
            })
        
        return detailed_results 