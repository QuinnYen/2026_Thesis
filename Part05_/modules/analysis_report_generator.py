"""
åˆ†æçµæœå ±å‘Šç”Ÿæˆå™¨ - å°‡æ‰€æœ‰æ­¥é©Ÿçš„åˆ†æçµæœè¼¸å‡ºç‚ºè©³ç´°çš„txtå ±å‘Š
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Optional, Any

class AnalysisReportGenerator:
    """åˆ†æçµæœå ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = None):
        """åˆå§‹åŒ–å ±å‘Šç”Ÿæˆå™¨"""
        self.output_dir = output_dir or "."
        self.report_filename = None
        
    def generate_comprehensive_report(self, 
                                   pipeline_results: Dict[str, Any],
                                   output_filename: str = None) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„åˆ†æçµæœå ±å‘Š
        
        Args:
            pipeline_results: èåˆç®¡ç·šçš„å®Œæ•´çµæœ
            output_filename: è¼¸å‡ºæª”æ¡ˆåç¨±
            
        Returns:
            ç”Ÿæˆçš„å ±å‘Šæª”æ¡ˆè·¯å¾‘
        """
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"æƒ…æ„Ÿåˆ†æ_æ–¹æ¡ˆA_å®Œæ•´å ±å‘Š_{timestamp}.txt"
        
        self.report_filename = os.path.join(self.output_dir, output_filename)
        
        # ç”Ÿæˆå ±å‘Šå…§å®¹
        report_content = self._build_report_content(pipeline_results)
        
        # å¯«å…¥æª”æ¡ˆ
        with open(self.report_filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“ å®Œæ•´åˆ†æå ±å‘Šå·²ç”Ÿæˆ: {self.report_filename}")
        return self.report_filename
    
    def _build_report_content(self, results: Dict[str, Any]) -> str:
        """æ§‹å»ºå ±å‘Šå…§å®¹"""
        lines = []
        
        # å ±å‘Šæ¨™é¡Œ
        lines.append("=" * 100)
        lines.append("æƒ…æ„Ÿåˆ†æç³»çµ± - æ–¹æ¡ˆAå®Œæ•´åˆ†æå ±å‘Š")
        lines.append("=" * 100)
        lines.append(f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        lines.append("")
        
        # ç³»çµ±è³‡è¨Š
        lines.extend(self._generate_system_info(results))
        
        # æ•¸æ“šé è™•ç†çµæœ
        lines.extend(self._generate_preprocessing_section(results))
        
        # æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ
        lines.extend(self._generate_attention_analysis(results))
        
        # GFNé–€æ§èåˆåˆ†æ
        lines.extend(self._generate_gfn_analysis(results))
        
        # åˆ†é¡çµæœåˆ†æ
        lines.extend(self._generate_classification_analysis(results))
        
        # æ€§èƒ½æ¯”è¼ƒåˆ†æ
        lines.extend(self._generate_performance_analysis(results))
        
        # éšæ®µåŸ·è¡Œæ™‚é–“åˆ†æ
        lines.extend(self._generate_timing_analysis(results))
        
        # çµè«–å’Œå»ºè­°
        lines.extend(self._generate_conclusions(results))
        
        return "\n".join(lines)
    
    def _generate_system_info(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç³»çµ±è³‡è¨Šéƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ“‹ ç³»çµ±é…ç½®è³‡è¨Š")
        lines.append("-" * 80)
        
        pipeline_info = results.get('pipeline_info', {})
        lines.append(f"æ¶æ§‹é¡å‹: {pipeline_info.get('architecture', 'N/A')}")
        lines.append(f"ç·¨ç¢¼å™¨: {pipeline_info.get('encoder_type', 'N/A').upper()}")
        lines.append(f"é–‹å§‹æ™‚é–“: {pipeline_info.get('start_time', 'N/A')}")
        
        # æ•¸æ“šåŸºæœ¬è³‡è¨Š
        preprocessing = results.get('preprocessing_results', {})
        lines.append(f"åŸå§‹æ•¸æ“šè¦æ¨¡: {preprocessing.get('original_shape', 'N/A')}")
        lines.append(f"è™•ç†å¾Œæ•¸æ“šè¦æ¨¡: {preprocessing.get('processed_shape', 'N/A')}")
        
        lines.append("")
        return lines
    
    def _generate_preprocessing_section(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ•¸æ“šé è™•ç†çµæœéƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ“Š æ•¸æ“šé è™•ç†çµæœ")
        lines.append("-" * 80)
        
        preprocessing = results.get('preprocessing_results', {})
        
        # æƒ…æ„Ÿæ¨™ç±¤åˆ†ä½ˆ
        sentiment_encoding = preprocessing.get('sentiment_encoding', {})
        if sentiment_encoding:
            lines.append("æƒ…æ„Ÿæ¨™ç±¤ç·¨ç¢¼åˆ†ä½ˆ:")
            for label, count in sentiment_encoding.items():
                lines.append(f"  {label}: {count} æ¢è¨˜éŒ„")
        
        # æ–‡æœ¬é è™•ç†çµ±è¨ˆ
        text_stats = preprocessing.get('text_statistics', {})
        if text_stats:
            lines.append("\næ–‡æœ¬é è™•ç†çµ±è¨ˆ:")
            lines.append(f"  å¹³å‡æ–‡æœ¬é•·åº¦: {text_stats.get('avg_length', 'N/A')}")
            lines.append(f"  æœ€é•·æ–‡æœ¬: {text_stats.get('max_length', 'N/A')} è©")
            lines.append(f"  æœ€çŸ­æ–‡æœ¬: {text_stats.get('min_length', 'N/A')} è©")
        
        lines.append("")
        return lines
    
    def _generate_attention_analysis(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æéƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ§  æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ")
        lines.append("-" * 80)
        
        # æŸ¥æ‰¾æ³¨æ„åŠ›éšæ®µ
        stages = results.get('pipeline_info', {}).get('stages', [])
        attention_stage = next((s for s in stages if s.get('stage') == 3), None)
        
        if attention_stage:
            lines.append("ä¸‰ç¨®æ³¨æ„åŠ›æ©Ÿåˆ¶ä¸¦è¡Œè¨ˆç®—çµæœ:")
            
            # ç‰¹å¾µå½¢ç‹€
            feature_shapes = attention_stage.get('feature_shapes', {})
            for mechanism, shape in feature_shapes.items():
                lines.append(f"  {mechanism.capitalize()} Attention: {shape}")
            
            # æ³¨æ„åŠ›æ©Ÿåˆ¶è©³ç´°è³‡è¨Š
            attention_info = attention_stage.get('attention_info', {})
            if attention_info:
                lines.append(f"\nè¨ˆç®—çš„æ³¨æ„åŠ›æ©Ÿåˆ¶æ•¸é‡: {attention_info.get('mechanisms_computed', 0)}")
                
            lines.append(f"\nåŸ·è¡Œæ™‚é–“: {attention_stage.get('duration_seconds', 0):.2f} ç§’")
        
        lines.append("")
        return lines
    
    def _generate_gfn_analysis(self, results: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆGFNé–€æ§èåˆåˆ†æéƒ¨åˆ†"""
        lines = []
        lines.append("âš¡ GFNé–€æ§èåˆç¶²è·¯åˆ†æ")
        lines.append("-" * 80)
        
        # æŸ¥æ‰¾GFNèåˆéšæ®µ
        stages = results.get('pipeline_info', {}).get('stages', [])
        fusion_stage = next((s for s in stages if s.get('stage') == 4), None)
        
        if fusion_stage:
            fusion_info = fusion_stage.get('fusion_info', {})
            
            # æ¬Šé‡åˆ†é…åˆ†æ
            avg_weights = fusion_info.get('average_weights', {})
            if avg_weights:
                lines.append("æ™ºèƒ½æ¬Šé‡å­¸ç¿’çµæœ:")
                total_weight = sum(avg_weights.values())
                
                for mechanism, weight in avg_weights.items():
                    percentage = (weight / total_weight * 100) if total_weight > 0 else 0
                    lines.append(f"  {mechanism.capitalize()}: {weight:.4f} ({percentage:.1f}%)")
                
                lines.append(f"  æ¬Šé‡ç¸½å’Œ: {total_weight:.4f}")
                
                # æ¬Šé‡åˆ†æ
                lines.append("\næ¬Šé‡åˆ†æ:")
                max_mechanism = max(avg_weights, key=avg_weights.get)
                min_mechanism = min(avg_weights, key=avg_weights.get)
                lines.append(f"  ä¸»å°æ©Ÿåˆ¶: {max_mechanism.capitalize()} ({avg_weights[max_mechanism]:.4f})")
                lines.append(f"  æ¬¡è¦æ©Ÿåˆ¶: {min_mechanism.capitalize()} ({avg_weights[min_mechanism]:.4f})")
                
                # æ¬Šé‡å‡è¡¡æ€§åˆ†æ
                weight_values = list(avg_weights.values())
                mean_weight = sum(weight_values) / len(weight_values)
                weight_variance = sum((w - mean_weight) ** 2 for w in weight_values) / len(weight_values)
                if weight_variance < 0.01:
                    balance_status = "é«˜åº¦å‡è¡¡"
                elif weight_variance < 0.05:
                    balance_status = "é©åº¦å‡è¡¡"
                else:
                    balance_status = "åå‘ç‰¹å®šæ©Ÿåˆ¶"
                lines.append(f"  æ¬Šé‡åˆ†ä½ˆ: {balance_status} (æ–¹å·®: {weight_variance:.6f})")
            
            # èåˆç‰¹å¾µè³‡è¨Š
            fused_shape = fusion_stage.get('fused_features_shape')
            if fused_shape:
                lines.append(f"\nèåˆç‰¹å¾µç¶­åº¦: {fused_shape}")
            
            lines.append(f"\nåŸ·è¡Œæ™‚é–“: {fusion_stage.get('duration_seconds', 0):.2f} ç§’")
        
        lines.append("")
        return lines
    
    def _generate_classification_analysis(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆåˆ†é¡çµæœåˆ†æéƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ¯ åˆ†é¡çµæœåˆ†æ")
        lines.append("-" * 80)
        
        # æŸ¥æ‰¾åˆ†é¡éšæ®µ
        stages = results.get('pipeline_info', {}).get('stages', [])
        classification_stage = next((s for s in stages if s.get('stage') == 5), None)
        
        if classification_stage:
            classification_results = classification_stage.get('classification_results', {})
            
            lines.append("æ¨¡å‹æ€§èƒ½æŒ‡æ¨™:")
            metrics = [
                ('æº–ç¢ºç‡', 'test_accuracy'),
                ('F1åˆ†æ•¸', 'test_f1'),
                ('ç²¾ç¢ºåº¦', 'test_precision'),
                ('å¬å›ç‡', 'test_recall')
            ]
            
            for metric_name, metric_key in metrics:
                value = classification_results.get(metric_key, 0)
                lines.append(f"  {metric_name}: {value:.4f} ({value*100:.2f}%)")
            
            lines.append(f"\nåŸ·è¡Œæ™‚é–“: {classification_stage.get('duration_seconds', 0):.2f} ç§’")
        
        # åˆ†é¡å ±å‘Šè©³ç´°è³‡è¨Š
        classification_full = results.get('classification_results', {})
        if classification_full:
            # æ··æ·†çŸ©é™£
            confusion_matrix = classification_full.get('confusion_matrix')
            if confusion_matrix is not None:
                lines.append("\næ··æ·†çŸ©é™£:")
                if isinstance(confusion_matrix, (list, tuple)):
                    for i, row in enumerate(confusion_matrix):
                        row_str = "  " + " ".join([f"{val:4d}" for val in row])
                        lines.append(row_str)
            
            # åˆ†é¡å ±å‘Š
            classification_report = classification_full.get('classification_report_dict')
            if classification_report:
                lines.append("\nå„é¡åˆ¥è©³ç´°æ€§èƒ½:")
                class_names = {0: 'è² é¢', 1: 'ä¸­æ€§', 2: 'æ­£é¢'}
                
                for class_idx in [0, 1, 2]:
                    if str(class_idx) in classification_report:
                        class_info = classification_report[str(class_idx)]
                        class_name = class_names.get(class_idx, f"é¡åˆ¥{class_idx}")
                        lines.append(f"  {class_name}:")
                        lines.append(f"    ç²¾ç¢ºåº¦: {class_info.get('precision', 0):.4f}")
                        lines.append(f"    å¬å›ç‡: {class_info.get('recall', 0):.4f}")
                        lines.append(f"    F1åˆ†æ•¸: {class_info.get('f1-score', 0):.4f}")
                        lines.append(f"    æ”¯æ´æ¨£æœ¬: {class_info.get('support', 0)}")
        
        lines.append("")
        return lines
    
    def _generate_performance_analysis(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½æ¯”è¼ƒåˆ†æéƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ“ˆ æ€§èƒ½åˆ†æèˆ‡æ¯”è¼ƒ")
        lines.append("-" * 80)
        
        # æŸ¥æ‰¾æº–ç¢ºç‡åˆ†æéšæ®µ
        stages = results.get('pipeline_info', {}).get('stages', [])
        analysis_stage = next((s for s in stages if s.get('stage') == 6), None)
        
        if analysis_stage:
            accuracy_analysis = analysis_stage.get('accuracy_analysis', {})
            
            # åŸå§‹æ¨™ç±¤vsé æ¸¬æ¨™ç±¤æ¯”è¼ƒ
            if accuracy_analysis:
                lines.append("åŸå§‹æ¨™ç±¤èˆ‡é æ¸¬çµæœæ¯”è¼ƒ:")
                lines.append(f"  æ•´é«”ä¸€è‡´æ€§: å·²å®Œæˆåˆ†æ")
                
            lines.append(f"\nåŸ·è¡Œæ™‚é–“: {analysis_stage.get('duration_seconds', 0):.2f} ç§’")
        
        # èåˆvså‚³çµ±æ–¹æ³•æ¯”è¼ƒ
        fusion_results = results.get('fusion_comparison', {})
        if fusion_results:
            lines.append("\næ–¹æ¡ˆAèåˆæ¶æ§‹ vs å‚³çµ±æ–¹æ³•:")
            lines.append(f"  GFNèåˆæº–ç¢ºç‡: {fusion_results.get('fusion_accuracy', 0):.4f}")
            lines.append(f"  å‚³çµ±æ–¹æ³•æº–ç¢ºç‡: {fusion_results.get('baseline_accuracy', 0):.4f}")
            improvement = fusion_results.get('improvement', 0)
            lines.append(f"  æ€§èƒ½æå‡: +{improvement:.4f} ({improvement*100:.2f}%)")
        
        lines.append("")
        return lines
    
    def _generate_timing_analysis(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ™‚é–“åˆ†æéƒ¨åˆ†"""
        lines = []
        lines.append("â±ï¸ åŸ·è¡Œæ™‚é–“åˆ†æ")
        lines.append("-" * 80)
        
        stages = results.get('pipeline_info', {}).get('stages', [])
        total_time = sum(stage.get('duration_seconds', 0) for stage in stages)
        
        lines.append("å„éšæ®µåŸ·è¡Œæ™‚é–“:")
        for stage in stages:
            stage_num = stage.get('stage', 0)
            stage_name = stage.get('name', 'æœªçŸ¥éšæ®µ')
            duration = stage.get('duration_seconds', 0)
            percentage = (duration / total_time * 100) if total_time > 0 else 0
            
            lines.append(f"  éšæ®µ{stage_num} - {stage_name}:")
            lines.append(f"    åŸ·è¡Œæ™‚é–“: {duration:.2f} ç§’ ({percentage:.1f}%)")
        
        lines.append(f"\nç¸½åŸ·è¡Œæ™‚é–“: {total_time:.2f} ç§’")
        
        # æ€§èƒ½ç“¶é ¸åˆ†æ
        if stages:
            slowest_stage = max(stages, key=lambda x: x.get('duration_seconds', 0))
            lines.append(f"æœ€è€—æ™‚éšæ®µ: éšæ®µ{slowest_stage.get('stage')} - {slowest_stage.get('name')}")
            lines.append(f"è€—æ™‚: {slowest_stage.get('duration_seconds', 0):.2f} ç§’")
        
        lines.append("")
        return lines
    
    def _generate_conclusions(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆçµè«–å’Œå»ºè­°éƒ¨åˆ†"""
        lines = []
        lines.append("ğŸ’¡ çµè«–èˆ‡å»ºè­°")
        lines.append("-" * 80)
        
        # æ–¹æ¡ˆAæ¶æ§‹å„ªå‹¢åˆ†æ
        lines.append("æ–¹æ¡ˆAæ¶æ§‹ç‰¹é»:")
        lines.append("  âœ… ä¸‰ç¨®æ³¨æ„åŠ›æ©Ÿåˆ¶ä¸¦è¡Œè¨ˆç®—ï¼Œå……åˆ†æ•æ‰æ–‡æœ¬ç‰¹å¾µ")
        lines.append("  âœ… GFNé–€æ§èåˆç¶²è·¯æ™ºèƒ½å­¸ç¿’æœ€å„ªæ¬Šé‡åˆ†é…")
        lines.append("  âœ… ç‰¹å¾µå°é½Šç¢ºä¿ç¶­åº¦ä¸€è‡´æ€§ï¼Œé¿å…è¨ˆç®—éŒ¯èª¤")
        lines.append("  âœ… End-to-Endè¨“ç·´ï¼Œè‡ªå‹•å„ªåŒ–æ•´é«”æ€§èƒ½")
        
        # æ€§èƒ½è©•ä¼°
        stages = results.get('pipeline_info', {}).get('stages', [])
        classification_stage = next((s for s in stages if s.get('stage') == 5), None)
        
        if classification_stage:
            accuracy = classification_stage.get('classification_results', {}).get('test_accuracy', 0)
            if accuracy >= 0.9:
                performance_level = "å„ªç§€"
            elif accuracy >= 0.8:
                performance_level = "è‰¯å¥½"
            elif accuracy >= 0.7:
                performance_level = "ä¸­ç­‰"
            else:
                performance_level = "å¾…æ”¹é€²"
            
            lines.append(f"\næ¨¡å‹æ€§èƒ½è©•ä¼°: {performance_level} (æº–ç¢ºç‡: {accuracy:.4f})")
        
        # GFNæ¬Šé‡åˆ†æå»ºè­°
        fusion_stage = next((s for s in stages if s.get('stage') == 4), None)
        if fusion_stage:
            avg_weights = fusion_stage.get('fusion_info', {}).get('average_weights', {})
            if avg_weights:
                max_mechanism = max(avg_weights, key=avg_weights.get)
                lines.append(f"\nGFNå­¸ç¿’çµæœ: {max_mechanism.capitalize()} æ³¨æ„åŠ›æ©Ÿåˆ¶è²¢ç»æœ€å¤§")
                
                weight_values = list(avg_weights.values())
                mean_weight = sum(weight_values) / len(weight_values) 
                weight_variance = sum((w - mean_weight) ** 2 for w in weight_values) / len(weight_values)
                if weight_variance > 0.05:
                    lines.append("å»ºè­°: æ¬Šé‡åˆ†ä½ˆä¸å‡å‹»ï¼Œå¯è€ƒæ…®èª¿æ•´æ³¨æ„åŠ›æ©Ÿåˆ¶åƒæ•¸")
                else:
                    lines.append("æ¬Šé‡åˆ†é…åˆç†ï¼Œå„æ³¨æ„åŠ›æ©Ÿåˆ¶å”èª¿é…åˆ")
        
        # æ”¹é€²å»ºè­°
        lines.append("\næ”¹é€²å»ºè­°:")
        lines.append("  ğŸ”§ å¯å˜—è©¦èª¿æ•´GFNéš±è—å±¤ç¶­åº¦ä»¥å„ªåŒ–èåˆæ•ˆæœ")
        lines.append("  ğŸ”§ è€ƒæ…®å¢åŠ æ•¸æ“šé è™•ç†æ­¥é©Ÿä»¥æé«˜æ–‡æœ¬è³ªé‡")
        lines.append("  ğŸ”§ å¯å¯¦é©—ä¸åŒçš„æ³¨æ„åŠ›æ©Ÿåˆ¶çµ„åˆ")
        lines.append("  ğŸ”§ é©ç•¶èª¿æ•´è¨“ç·´åƒæ•¸ä»¥é¿å…éæ“¬åˆ")
        
        lines.append("")
        lines.append("=" * 100)
        lines.append("å ±å‘ŠçµæŸ")
        lines.append("=" * 100)
        
        return lines