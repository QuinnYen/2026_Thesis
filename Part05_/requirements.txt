# 模組化情感分析系統 - 依賴套件清單
# =========================================
# 更新日期: 2025-06-12
# 系統：跨領域情感分析與多重編碼器/分類器架構平台
# 功能：BERT/GPT/T5編碼器 + XGBoost/邏輯迴歸/隨機森林/SVM分類器 + 注意力機制分析

# ============================
# 核心依賴套件 (必需安裝)
# ============================

# 深度學習框架
# ============
torch>=1.9.0,<2.1.0          # PyTorch深度學習框架，支援CUDA加速，用於BERT編碼和注意力機制
transformers>=4.0.0,<5.0.0   # Hugging Face Transformers：BERT/GPT/T5等預訓練模型
tokenizers>=0.13.0,<1.0.0    # 高速分詞器（Transformers依賴，自動安裝）

# 機器學習核心套件
# ================
scikit-learn>=1.0.0,<1.4.0   # 機器學習工具包：邏輯迴歸、隨機森林、SVM、評估指標、數據預處理
xgboost>=1.6.0,<2.1.0        # 高性能梯度提升樹分類器（預設分類器），支援GPU加速
numpy>=1.21.0,<1.26.0        # 數值計算基礎庫，用於特徵向量處理
pandas>=1.3.0,<2.1.0         # 數據分析與操作庫，用於CSV讀寫和數據框操作

# 自然語言處理
# ============
nltk>=3.6,<4.0               # 自然語言處理工具包：分詞、停用詞移除、語言資源
beautifulsoup4>=4.9.0,<5.0.0 # HTML解析器，用於文本清理和預處理

# 工具套件
# ========
tqdm>=4.60.0,<5.0.0          # 進度條顯示，用於GUI進度追蹤
joblib>=1.0.0,<2.0.0         # 高效序列化庫，用於模型持久化和向量保存

# ============================
# 進階功能套件 (可選安裝)
# ============================

# 主題建模與分群分析
# ==================
gensim>=4.0.0,<5.0.0         # 主題建模庫：LDA主題分析（實際使用）
bertopic>=0.9.0,<1.0.0       # 基於BERT的進階主題建模（實際使用）
umap-learn>=0.5.0,<1.0.0     # 非線性降維算法（BERTopic依賴，實際使用）
hdbscan>=0.8.0,<1.0.0        # 密度聚類算法（BERTopic依賴，實際使用）

# 科學計算擴展
# ============
scipy>=1.7.0,<1.12.0         # 科學計算庫，用於數值優化和統計分析

# ============================
# 特殊編碼器套件 (高級功能)
# ============================
# 注意：以下套件為進階功能，需要額外配置和大量記憶體
# allennlp>=2.0.0,<3.0.0       # ELMo文本編碼器支援（可選，需8GB+ RAM）
# allennlp-models>=2.0.0,<3.0.0 # ELMo預訓練模型（可選，需大量磁碟空間）

# =====================================
# 安裝指南：
# =====================================

# 🚀 方案一：最小安裝（僅核心功能，約1.5GB）
# 推薦初次安裝或記憶體有限環境
#pip install torch>=1.9.0 transformers>=4.0.0 scikit-learn>=1.0.0 xgboost>=1.6.0 numpy>=1.21.0 pandas>=1.3.0 nltk>=3.6 beautifulsoup4>=4.9.0 tqdm>=4.60.0 joblib>=1.0.0

# 🌟 方案二：進階安裝（包含主題建模，約2.5GB）
# 推薦大部分使用情境
#pip install torch>=1.9.0 transformers>=4.0.0 scikit-learn>=1.0.0 xgboost>=1.6.0 numpy>=1.21.0 pandas>=1.3.0 nltk>=3.6 beautifulsoup4>=4.9.0 tqdm>=4.60.0 joblib>=1.0.0 gensim>=4.0.0 bertopic>=0.9.0 umap-learn>=0.5.0 hdbscan>=0.8.0 scipy>=1.7.0

# 💪 方案三：完整安裝（所有功能）
#pip install -r requirements.txt

# 🎮 GPU加速安裝（強烈推薦，提升10-50倍速度）
# 步驟1：安裝CUDA版本的PyTorch
#pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
# 步驟2：安裝其餘套件
#pip install -r requirements.txt

# =====================================
# 驗證安裝：
# =====================================

# ✅ 驗證核心功能
#python -c "import torch, transformers, sklearn, xgboost, pandas, numpy; print('✅ 核心套件安裝成功')"

# ✅ 驗證模組化架構
#python -c "from modules.encoder_factory import EncoderFactory; from modules.aspect_factory import AspectFactory; print('✅ 模組化架構可用')"

# ✅ 驗證GPU支援（可選）
#python -c "import torch; print(f'✅ GPU可用: {torch.cuda.is_available()}, 設備數量: {torch.cuda.device_count()}')"

# ✅ 驗證進階功能（可選）
#python -c "import bertopic, umap, hdbscan; print('✅ 進階主題建模套件可用')"

# =====================================
# 系統需求：
# =====================================
# 🖥️  Python: 3.8+ (建議3.9+)
# 💾 記憶體: 8GB 最低 / 16GB 推薦 / 32GB 大規模實驗
# 🎮 GPU: 4GB+ VRAM (可選，用於加速) / 8GB+ 大模型
# 💿 磁碟: 10GB+ (包含模型下載)
# 🌐 網路: 首次使用需下載BERT模型（約2-5GB）

# =====================================
# 首次運行設定：
# =====================================

# 📥 下載NLTK語言資源
#python -c "import nltk; nltk.download(['punkt', 'stopwords', 'wordnet', 'omw-1.4'])"

# 🤖 BERT模型會在首次使用時自動下載
# 位置：~/.cache/huggingface/transformers/

# =====================================
# 常見問題解決：
# =====================================

# 🔧 升級pip（安裝失敗時）
#python -m pip install --upgrade pip

# 🚀 使用國內鏡像（網路問題）
#pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/

# 💻 強制使用CPU（CUDA錯誤）
#export CUDA_VISIBLE_DEVICES=""

# 🧹 清理快取（磁碟空間不足）
#pip cache purge

# =====================================